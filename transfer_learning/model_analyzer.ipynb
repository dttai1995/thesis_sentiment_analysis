{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_nWetWWd_ns",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Copyright 2021 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "2pHVBk_seED1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7vSdG6sAIQn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TensorFlow Lite Model Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwc5GKHBASdc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/lite/guide/model_analyzer\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/guide/model_analyzer.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/guide/model_analyzer.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/tensorflow/tensorflow/lite/g3doc/guide/model_analyzer.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ee074e4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "TensorFlow Lite Model Analyzer API helps you analyze models in TensorFlow Lite format by listing a model's structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKwW0VfDKMWS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Analyzer API\n",
    "\n",
    "The following API is available for the TensorFlow Lite Model Analyzer.\n",
    "\n",
    "```\n",
    "tf.lite.experimental.Analyzer.analyze(model_path=None,\n",
    "                                      model_content=None,\n",
    "                                      gpu_compatibility=False)\n",
    "```\n",
    "\n",
    "You can find the API details from https://www.tensorflow.org/api_docs/python/tf/lite/experimental/Analyzer or run `help(tf.lite.experimental.Analyzer.analyze)` from a Python terminal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qi8Vk4_065jN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Basic usage with simple Keras model\n",
    "\n",
    "The following code shows basic usage of Model Analyzer. It shows contents of the converted Keras model in TFLite model content, formatted as a flatbuffer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_jkg6UNtdz8c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\admin\\AppData\\Local\\Temp\\tmpvm_7t7v7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TFLite ModelAnalyzer ===\n",
      "\n",
      "Your TFLite model has '1' subgraph(s). In the subgraph description below,\n",
      "T# represents the Tensor numbers. For example, in Subgraph#0, the RESHAPE op takes\n",
      "tensor #0 and tensor #1 as input and produces tensor #4 as output.\n",
      "\n",
      "Subgraph#0 main(T#0) -> [T#6]\n",
      "  Op#0 RESHAPE(T#0, T#1) -> [T#4]\n",
      "  Op#1 FULLY_CONNECTED(T#4, T#2, T#-1) -> [T#5]\n",
      "  Op#2 FULLY_CONNECTED(T#5, T#3, T#-1) -> [T#6]\n",
      "\n",
      "Tensors of Subgraph#0\n",
      "  T#0(serving_default_flatten_input:0) shape_signature:[-1, 128, 128], type:FLOAT32\n",
      "  T#1(sequential/flatten/Const) shape:[2], type:INT32 RO 8 bytes\n",
      "  T#2(sequential/dense/MatMul) shape:[256, 16384], type:FLOAT32 RO 16777216 bytes\n",
      "  T#3(sequential/dense_1/MatMul) shape:[10, 256], type:FLOAT32 RO 10240 bytes\n",
      "  T#4(sequential/flatten/Reshape) shape_signature:[-1, 16384], type:FLOAT32\n",
      "  T#5(sequential/dense/MatMul;sequential/dense/Relu;sequential/dense/BiasAdd) shape_signature:[-1, 256], type:FLOAT32\n",
      "  T#6(StatefulPartitionedCall:0) shape_signature:[-1, 10], type:FLOAT32\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Your TFLite model has ‘1’ signature_def(s).\n",
      "\n",
      "Signature#0 key: 'serving_default'\n",
      "- Subgraph: Subgraph#0\n",
      "- Inputs: \n",
      "    'flatten_input' : T#0\n",
      "- Outputs: \n",
      "    'dense_1' : T#6\n",
      "\n",
      "---------------------------------------------------------------\n",
      "              Model size:   16788864 bytes\n",
      "    Non-data buffer size:       1384 bytes (00.01 %)\n",
      "  Total data buffer size:   16787480 bytes (99.99 %)\n",
      "    (Zero value buffers):          0 bytes (00.00 %)\n",
      "\n",
      "* Buffers of TFLite model are mostly used for constant tensors.\n",
      "  And zero value buffers are buffers filled with zeros.\n",
      "  Non-data buffers area are used to store operators, subgraphs and etc.\n",
      "  You can find more details from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(128, 128)),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "fb_model = tf.lite.TFLiteConverter.from_keras_model(model).convert()\n",
    "\n",
    "tf.lite.experimental.Analyzer.analyze(model_content=fb_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pe_ZU5Zy7PeH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Basic usage with MobileNetV3Large Keras model\n",
    "\n",
    "This API works with large models such as MobileNetV3Large. Since the output is large, you might want to browse it with your favorite text editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QFywJ_g56VW5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float.h5\n",
      "22667264/22661472 [==============================] - 6s 0us/step\n",
      "22675456/22661472 [==============================] - 6s 0us/step\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\admin\\AppData\\Local\\Temp\\tmp1ao97uoh\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\admin\\AppData\\Local\\Temp\\tmp1ao97uoh\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TFLite ModelAnalyzer ===\n",
      "\n",
      "Your TFLite model has '1' subgraph(s). In the subgraph description below,\n",
      "T# represents the Tensor numbers. For example, in Subgraph#0, the MUL op takes\n",
      "tensor #0 and tensor #19 as input and produces tensor #136 as output.\n",
      "\n",
      "Subgraph#0 main(T#0) -> [T#263]\n",
      "  Op#0 MUL(T#0, T#19) -> [T#136]\n",
      "  Op#1 ADD(T#136, T#18) -> [T#137]\n",
      "  Op#2 CONV_2D(T#137, T#44, T#93) -> [T#138]\n",
      "  Op#3 HARD_SWISH(T#138) -> [T#139]\n",
      "  Op#4 DEPTHWISE_CONV_2D(T#139, T#94, T#24) -> [T#140]\n",
      "  Op#5 CONV_2D(T#140, T#45, T#95) -> [T#141]\n",
      "  Op#6 ADD(T#139, T#141) -> [T#142]\n",
      "  Op#7 CONV_2D(T#142, T#46, T#25) -> [T#143]\n",
      "  Op#8 PAD(T#143, T#22) -> [T#144]\n",
      "  Op#9 DEPTHWISE_CONV_2D(T#144, T#96, T#26) -> [T#145]\n",
      "  Op#10 CONV_2D(T#145, T#47, T#97) -> [T#146]\n",
      "  Op#11 CONV_2D(T#146, T#48, T#27) -> [T#147]\n",
      "  Op#12 DEPTHWISE_CONV_2D(T#147, T#98, T#28) -> [T#148]\n",
      "  Op#13 CONV_2D(T#148, T#49, T#99) -> [T#149]\n",
      "  Op#14 ADD(T#146, T#149) -> [T#150]\n",
      "  Op#15 CONV_2D(T#150, T#50, T#29) -> [T#151]\n",
      "  Op#16 PAD(T#151, T#23) -> [T#152]\n",
      "  Op#17 DEPTHWISE_CONV_2D(T#152, T#100, T#30) -> [T#153]\n",
      "  Op#18 MEAN(T#153, T#20) -> [T#154]\n",
      "  Op#19 CONV_2D(T#154, T#51, T#3) -> [T#155]\n",
      "  Op#20 CONV_2D(T#155, T#52, T#10) -> [T#156]\n",
      "  Op#21 MUL(T#156, T#9) -> [T#157]\n",
      "  Op#22 MUL(T#153, T#157) -> [T#158]\n",
      "  Op#23 CONV_2D(T#158, T#53, T#101) -> [T#159]\n",
      "  Op#24 CONV_2D(T#159, T#54, T#31) -> [T#160]\n",
      "  Op#25 DEPTHWISE_CONV_2D(T#160, T#102, T#32) -> [T#161]\n",
      "  Op#26 MEAN(T#161, T#20) -> [T#162]\n",
      "  Op#27 CONV_2D(T#162, T#55, T#2) -> [T#163]\n",
      "  Op#28 CONV_2D(T#163, T#56, T#11) -> [T#164]\n",
      "  Op#29 MUL(T#164, T#9) -> [T#165]\n",
      "  Op#30 MUL(T#161, T#165) -> [T#166]\n",
      "  Op#31 CONV_2D(T#166, T#57, T#103) -> [T#167]\n",
      "  Op#32 ADD(T#159, T#167) -> [T#168]\n",
      "  Op#33 CONV_2D(T#168, T#58, T#33) -> [T#169]\n",
      "  Op#34 DEPTHWISE_CONV_2D(T#169, T#104, T#34) -> [T#170]\n",
      "  Op#35 MEAN(T#170, T#20) -> [T#171]\n",
      "  Op#36 CONV_2D(T#171, T#59, T#1) -> [T#172]\n",
      "  Op#37 CONV_2D(T#172, T#60, T#12) -> [T#173]\n",
      "  Op#38 MUL(T#173, T#9) -> [T#174]\n",
      "  Op#39 MUL(T#170, T#174) -> [T#175]\n",
      "  Op#40 CONV_2D(T#175, T#61, T#105) -> [T#176]\n",
      "  Op#41 ADD(T#168, T#176) -> [T#177]\n",
      "  Op#42 CONV_2D(T#177, T#62, T#106) -> [T#178]\n",
      "  Op#43 HARD_SWISH(T#178) -> [T#179]\n",
      "  Op#44 PAD(T#179, T#22) -> [T#180]\n",
      "  Op#45 DEPTHWISE_CONV_2D(T#180, T#107, T#35) -> [T#181]\n",
      "  Op#46 HARD_SWISH(T#181) -> [T#182]\n",
      "  Op#47 CONV_2D(T#182, T#63, T#108) -> [T#183]\n",
      "  Op#48 CONV_2D(T#183, T#64, T#109) -> [T#184]\n",
      "  Op#49 HARD_SWISH(T#184) -> [T#185]\n",
      "  Op#50 DEPTHWISE_CONV_2D(T#185, T#110, T#36) -> [T#186]\n",
      "  Op#51 HARD_SWISH(T#186) -> [T#187]\n",
      "  Op#52 CONV_2D(T#187, T#65, T#111) -> [T#188]\n",
      "  Op#53 ADD(T#183, T#188) -> [T#189]\n",
      "  Op#54 CONV_2D(T#189, T#66, T#112) -> [T#190]\n",
      "  Op#55 HARD_SWISH(T#190) -> [T#191]\n",
      "  Op#56 DEPTHWISE_CONV_2D(T#191, T#113, T#37) -> [T#192]\n",
      "  Op#57 HARD_SWISH(T#192) -> [T#193]\n",
      "  Op#58 CONV_2D(T#193, T#67, T#114) -> [T#194]\n",
      "  Op#59 ADD(T#189, T#194) -> [T#195]\n",
      "  Op#60 CONV_2D(T#195, T#68, T#115) -> [T#196]\n",
      "  Op#61 HARD_SWISH(T#196) -> [T#197]\n",
      "  Op#62 DEPTHWISE_CONV_2D(T#197, T#116, T#38) -> [T#198]\n",
      "  Op#63 HARD_SWISH(T#198) -> [T#199]\n",
      "  Op#64 CONV_2D(T#199, T#69, T#117) -> [T#200]\n",
      "  Op#65 ADD(T#195, T#200) -> [T#201]\n",
      "  Op#66 CONV_2D(T#201, T#70, T#118) -> [T#202]\n",
      "  Op#67 HARD_SWISH(T#202) -> [T#203]\n",
      "  Op#68 DEPTHWISE_CONV_2D(T#203, T#119, T#39) -> [T#204]\n",
      "  Op#69 HARD_SWISH(T#204) -> [T#205]\n",
      "  Op#70 MEAN(T#205, T#20) -> [T#206]\n",
      "  Op#71 CONV_2D(T#206, T#71, T#8) -> [T#207]\n",
      "  Op#72 CONV_2D(T#207, T#72, T#13) -> [T#208]\n",
      "  Op#73 MUL(T#208, T#9) -> [T#209]\n",
      "  Op#74 MUL(T#205, T#209) -> [T#210]\n",
      "  Op#75 CONV_2D(T#210, T#73, T#120) -> [T#211]\n",
      "  Op#76 CONV_2D(T#211, T#74, T#121) -> [T#212]\n",
      "  Op#77 HARD_SWISH(T#212) -> [T#213]\n",
      "  Op#78 DEPTHWISE_CONV_2D(T#213, T#122, T#40) -> [T#214]\n",
      "  Op#79 HARD_SWISH(T#214) -> [T#215]\n",
      "  Op#80 MEAN(T#215, T#20) -> [T#216]\n",
      "  Op#81 CONV_2D(T#216, T#75, T#7) -> [T#217]\n",
      "  Op#82 CONV_2D(T#217, T#76, T#14) -> [T#218]\n",
      "  Op#83 MUL(T#218, T#9) -> [T#219]\n",
      "  Op#84 MUL(T#215, T#219) -> [T#220]\n",
      "  Op#85 CONV_2D(T#220, T#77, T#123) -> [T#221]\n",
      "  Op#86 ADD(T#211, T#221) -> [T#222]\n",
      "  Op#87 CONV_2D(T#222, T#78, T#124) -> [T#223]\n",
      "  Op#88 HARD_SWISH(T#223) -> [T#224]\n",
      "  Op#89 PAD(T#224, T#23) -> [T#225]\n",
      "  Op#90 DEPTHWISE_CONV_2D(T#225, T#125, T#41) -> [T#226]\n",
      "  Op#91 HARD_SWISH(T#226) -> [T#227]\n",
      "  Op#92 MEAN(T#227, T#20) -> [T#228]\n",
      "  Op#93 CONV_2D(T#228, T#79, T#6) -> [T#229]\n",
      "  Op#94 CONV_2D(T#229, T#80, T#15) -> [T#230]\n",
      "  Op#95 MUL(T#230, T#9) -> [T#231]\n",
      "  Op#96 MUL(T#227, T#231) -> [T#232]\n",
      "  Op#97 CONV_2D(T#232, T#81, T#126) -> [T#233]\n",
      "  Op#98 CONV_2D(T#233, T#82, T#127) -> [T#234]\n",
      "  Op#99 HARD_SWISH(T#234) -> [T#235]\n",
      "  Op#100 DEPTHWISE_CONV_2D(T#235, T#128, T#42) -> [T#236]\n",
      "  Op#101 HARD_SWISH(T#236) -> [T#237]\n",
      "  Op#102 MEAN(T#237, T#20) -> [T#238]\n",
      "  Op#103 CONV_2D(T#238, T#83, T#5) -> [T#239]\n",
      "  Op#104 CONV_2D(T#239, T#84, T#16) -> [T#240]\n",
      "  Op#105 MUL(T#240, T#9) -> [T#241]\n",
      "  Op#106 MUL(T#237, T#241) -> [T#242]\n",
      "  Op#107 CONV_2D(T#242, T#85, T#129) -> [T#243]\n",
      "  Op#108 ADD(T#233, T#243) -> [T#244]\n",
      "  Op#109 CONV_2D(T#244, T#86, T#130) -> [T#245]\n",
      "  Op#110 HARD_SWISH(T#245) -> [T#246]\n",
      "  Op#111 DEPTHWISE_CONV_2D(T#246, T#131, T#43) -> [T#247]\n",
      "  Op#112 HARD_SWISH(T#247) -> [T#248]\n",
      "  Op#113 MEAN(T#248, T#20) -> [T#249]\n",
      "  Op#114 CONV_2D(T#249, T#87, T#4) -> [T#250]\n",
      "  Op#115 CONV_2D(T#250, T#88, T#17) -> [T#251]\n",
      "  Op#116 MUL(T#251, T#9) -> [T#252]\n",
      "  Op#117 MUL(T#248, T#252) -> [T#253]\n",
      "  Op#118 CONV_2D(T#253, T#89, T#132) -> [T#254]\n",
      "  Op#119 ADD(T#244, T#254) -> [T#255]\n",
      "  Op#120 CONV_2D(T#255, T#90, T#133) -> [T#256]\n",
      "  Op#121 HARD_SWISH(T#256) -> [T#257]\n",
      "  Op#122 MEAN(T#257, T#20) -> [T#258]\n",
      "  Op#123 CONV_2D(T#258, T#91, T#134) -> [T#259]\n",
      "  Op#124 HARD_SWISH(T#259) -> [T#260]\n",
      "  Op#125 CONV_2D(T#260, T#92, T#135) -> [T#261]\n",
      "  Op#126 RESHAPE(T#261, T#21) -> [T#262]\n",
      "  Op#127 SOFTMAX(T#262) -> [T#263]\n",
      "\n",
      "Tensors of Subgraph#0\n",
      "  T#0(serving_default_input_1:0) shape_signature:[-1, -1, -1, 3], type:FLOAT32\n",
      "  T#1(expanded_conv_5/squeeze_excite/Conv/bias) shape:[32], type:FLOAT32 RO 128 bytes\n",
      "  T#2(expanded_conv_4/squeeze_excite/Conv/bias) shape:[32], type:FLOAT32 RO 128 bytes\n",
      "  T#3(expanded_conv_3/squeeze_excite/Conv/bias) shape:[24], type:FLOAT32 RO 96 bytes\n",
      "  T#4(expanded_conv_14/squeeze_excite/Conv/bias) shape:[240], type:FLOAT32 RO 960 bytes\n",
      "  T#5(expanded_conv_13/squeeze_excite/Conv/bias) shape:[240], type:FLOAT32 RO 960 bytes\n",
      "  T#6(expanded_conv_12/squeeze_excite/Conv/bias) shape:[168], type:FLOAT32 RO 672 bytes\n",
      "  T#7(expanded_conv_11/squeeze_excite/Conv/bias) shape:[168], type:FLOAT32 RO 672 bytes\n",
      "  T#8(expanded_conv_10/squeeze_excite/Conv/bias) shape:[120], type:FLOAT32 RO 480 bytes\n",
      "  T#9(MobilenetV3large/tf.math.multiply/Mul/y) shape:[], type:FLOAT32 RO 4 bytes\n",
      "  T#10(MobilenetV3large/re_lu_8/Relu6;MobilenetV3large/tf.__operators__.add_1/AddV2;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D;expanded_conv_3/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y) shape:[72], type:FLOAT32 RO 288 bytes\n",
      "  T#11(MobilenetV3large/re_lu_11/Relu6;MobilenetV3large/tf.__operators__.add_2/AddV2;MobilenetV3large/expanded_conv_4/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_4/squeeze_excite/Conv_1/Conv2D;expanded_conv_4/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y) shape:[120], type:FLOAT32 RO 480 bytes\n",
      "  T#12(MobilenetV3large/re_lu_14/Relu6;MobilenetV3large/tf.__operators__.add_3/AddV2;MobilenetV3large/expanded_conv_5/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_5/squeeze_excite/Conv_1/Conv2D;expanded_conv_5/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y) shape:[120], type:FLOAT32 RO 480 bytes\n",
      "  T#13(MobilenetV3large/re_lu_25/Relu6;MobilenetV3large/tf.__operators__.add_14/AddV2;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/Conv2D;expanded_conv_10/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y) shape:[480], type:FLOAT32 RO 1920 bytes\n",
      "  T#14(MobilenetV3large/re_lu_28/Relu6;MobilenetV3large/tf.__operators__.add_17/AddV2;MobilenetV3large/expanded_conv_11/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_11/squeeze_excite/Conv_1/Conv2D;expanded_conv_11/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y) shape:[672], type:FLOAT32 RO 2688 bytes\n",
      "  T#15(MobilenetV3large/re_lu_31/Relu6;MobilenetV3large/tf.__operators__.add_20/AddV2;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D;expanded_conv_12/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y) shape:[672], type:FLOAT32 RO 2688 bytes\n",
      "  T#16(MobilenetV3large/re_lu_34/Relu6;MobilenetV3large/tf.__operators__.add_23/AddV2;MobilenetV3large/expanded_conv_13/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_13/squeeze_excite/Conv_1/Conv2D;expanded_conv_13/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y) shape:[960], type:FLOAT32 RO 3840 bytes\n",
      "  T#17(MobilenetV3large/re_lu_37/Relu6;MobilenetV3large/tf.__operators__.add_26/AddV2;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv_1/Conv2D;expanded_conv_14/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y) shape:[960], type:FLOAT32 RO 3840 bytes\n",
      "  T#18(MobilenetV3large/rescaling/Cast_1/x) shape:[], type:FLOAT32 RO 4 bytes\n",
      "  T#19(MobilenetV3large/rescaling/Cast/x) shape:[], type:FLOAT32 RO 4 bytes\n",
      "  T#20(MobilenetV3large/expanded_conv_10/squeeze_excite/AvgPool/Mean/reduction_indices) shape:[2], type:INT32 RO 8 bytes\n",
      "  T#21(MobilenetV3large/flatten_1/Const) shape:[2], type:INT32 RO 8 bytes\n",
      "  T#22(MobilenetV3large/expanded_conv_1/depthwise/pad/Pad/paddings) shape:[4, 2], type:INT32 RO 32 bytes\n",
      "  T#23(MobilenetV3large/expanded_conv_12/depthwise/pad/Pad/paddings) shape:[4, 2], type:INT32 RO 32 bytes\n",
      "  T#24(MobilenetV3large/expanded_conv/depthwise/BatchNorm/FusedBatchNormV3) shape:[16], type:FLOAT32 RO 64 bytes\n",
      "  T#25(MobilenetV3large/expanded_conv_1/expand/BatchNorm/FusedBatchNormV3) shape:[64], type:FLOAT32 RO 256 bytes\n",
      "  T#26(MobilenetV3large/expanded_conv_1/depthwise/BatchNorm/FusedBatchNormV3) shape:[64], type:FLOAT32 RO 256 bytes\n",
      "  T#27(MobilenetV3large/expanded_conv_2/expand/BatchNorm/FusedBatchNormV3) shape:[72], type:FLOAT32 RO 288 bytes\n",
      "  T#28(MobilenetV3large/expanded_conv_2/depthwise/BatchNorm/FusedBatchNormV3) shape:[72], type:FLOAT32 RO 288 bytes\n",
      "  T#29(MobilenetV3large/expanded_conv_3/expand/BatchNorm/FusedBatchNormV3) shape:[72], type:FLOAT32 RO 288 bytes\n",
      "  T#30(MobilenetV3large/expanded_conv_3/depthwise/BatchNorm/FusedBatchNormV3) shape:[72], type:FLOAT32 RO 288 bytes\n",
      "  T#31(MobilenetV3large/expanded_conv_4/expand/BatchNorm/FusedBatchNormV3) shape:[120], type:FLOAT32 RO 480 bytes\n",
      "  T#32(MobilenetV3large/expanded_conv_4/depthwise/BatchNorm/FusedBatchNormV3) shape:[120], type:FLOAT32 RO 480 bytes\n",
      "  T#33(MobilenetV3large/expanded_conv_5/expand/BatchNorm/FusedBatchNormV3) shape:[120], type:FLOAT32 RO 480 bytes\n",
      "  T#34(MobilenetV3large/expanded_conv_5/depthwise/BatchNorm/FusedBatchNormV3) shape:[120], type:FLOAT32 RO 480 bytes\n",
      "  T#35(MobilenetV3large/expanded_conv_6/depthwise/BatchNorm/FusedBatchNormV3) shape:[240], type:FLOAT32 RO 960 bytes\n",
      "  T#36(MobilenetV3large/expanded_conv_7/depthwise/BatchNorm/FusedBatchNormV3) shape:[200], type:FLOAT32 RO 800 bytes\n",
      "  T#37(MobilenetV3large/expanded_conv_8/depthwise/BatchNorm/FusedBatchNormV3) shape:[184], type:FLOAT32 RO 736 bytes\n",
      "  T#38(MobilenetV3large/expanded_conv_9/depthwise/BatchNorm/FusedBatchNormV3) shape:[184], type:FLOAT32 RO 736 bytes\n",
      "  T#39(MobilenetV3large/expanded_conv_10/depthwise/BatchNorm/FusedBatchNormV3) shape:[480], type:FLOAT32 RO 1920 bytes\n",
      "  T#40(MobilenetV3large/expanded_conv_11/depthwise/BatchNorm/FusedBatchNormV3) shape:[672], type:FLOAT32 RO 2688 bytes\n",
      "  T#41(MobilenetV3large/expanded_conv_12/depthwise/BatchNorm/FusedBatchNormV3) shape:[672], type:FLOAT32 RO 2688 bytes\n",
      "  T#42(MobilenetV3large/expanded_conv_13/depthwise/BatchNorm/FusedBatchNormV3) shape:[960], type:FLOAT32 RO 3840 bytes\n",
      "  T#43(MobilenetV3large/expanded_conv_14/depthwise/BatchNorm/FusedBatchNormV3) shape:[960], type:FLOAT32 RO 3840 bytes\n",
      "  T#44(MobilenetV3large/Conv/Conv2D) shape:[16, 3, 3, 3], type:FLOAT32 RO 1728 bytes\n",
      "  T#45(MobilenetV3large/expanded_conv/project/Conv2D) shape:[16, 1, 1, 16], type:FLOAT32 RO 1024 bytes\n",
      "  T#46(MobilenetV3large/expanded_conv_1/expand/Conv2D) shape:[64, 1, 1, 16], type:FLOAT32 RO 4096 bytes\n",
      "  T#47(MobilenetV3large/expanded_conv_1/project/Conv2D) shape:[24, 1, 1, 64], type:FLOAT32 RO 6144 bytes\n",
      "  T#48(MobilenetV3large/expanded_conv_2/expand/Conv2D) shape:[72, 1, 1, 24], type:FLOAT32 RO 6912 bytes\n",
      "  T#49(MobilenetV3large/expanded_conv_2/project/Conv2D) shape:[24, 1, 1, 72], type:FLOAT32 RO 6912 bytes\n",
      "  T#50(MobilenetV3large/expanded_conv_3/expand/Conv2D) shape:[72, 1, 1, 24], type:FLOAT32 RO 6912 bytes\n",
      "  T#51(MobilenetV3large/expanded_conv_3/squeeze_excite/Conv/Conv2D) shape:[24, 1, 1, 72], type:FLOAT32 RO 6912 bytes\n",
      "  T#52(MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D) shape:[72, 1, 1, 24], type:FLOAT32 RO 6912 bytes\n",
      "  T#53(MobilenetV3large/expanded_conv_3/project/Conv2D) shape:[40, 1, 1, 72], type:FLOAT32 RO 11520 bytes\n",
      "  T#54(MobilenetV3large/expanded_conv_4/expand/Conv2D) shape:[120, 1, 1, 40], type:FLOAT32 RO 19200 bytes\n",
      "  T#55(MobilenetV3large/expanded_conv_4/squeeze_excite/Conv/Conv2D) shape:[32, 1, 1, 120], type:FLOAT32 RO 15360 bytes\n",
      "  T#56(MobilenetV3large/expanded_conv_4/squeeze_excite/Conv_1/Conv2D) shape:[120, 1, 1, 32], type:FLOAT32 RO 15360 bytes\n",
      "  T#57(MobilenetV3large/expanded_conv_4/project/Conv2D) shape:[40, 1, 1, 120], type:FLOAT32 RO 19200 bytes\n",
      "  T#58(MobilenetV3large/expanded_conv_5/expand/Conv2D) shape:[120, 1, 1, 40], type:FLOAT32 RO 19200 bytes\n",
      "  T#59(MobilenetV3large/expanded_conv_5/squeeze_excite/Conv/Conv2D) shape:[32, 1, 1, 120], type:FLOAT32 RO 15360 bytes\n",
      "  T#60(MobilenetV3large/expanded_conv_5/squeeze_excite/Conv_1/Conv2D) shape:[120, 1, 1, 32], type:FLOAT32 RO 15360 bytes\n",
      "  T#61(MobilenetV3large/expanded_conv_5/project/Conv2D) shape:[40, 1, 1, 120], type:FLOAT32 RO 19200 bytes\n",
      "  T#62(MobilenetV3large/expanded_conv_6/expand/Conv2D) shape:[240, 1, 1, 40], type:FLOAT32 RO 38400 bytes\n",
      "  T#63(MobilenetV3large/expanded_conv_6/project/Conv2D) shape:[80, 1, 1, 240], type:FLOAT32 RO 76800 bytes\n",
      "  T#64(MobilenetV3large/expanded_conv_7/expand/Conv2D) shape:[200, 1, 1, 80], type:FLOAT32 RO 64000 bytes\n",
      "  T#65(MobilenetV3large/expanded_conv_7/project/Conv2D) shape:[80, 1, 1, 200], type:FLOAT32 RO 64000 bytes\n",
      "  T#66(MobilenetV3large/expanded_conv_8/expand/Conv2D) shape:[184, 1, 1, 80], type:FLOAT32 RO 58880 bytes\n",
      "  T#67(MobilenetV3large/expanded_conv_8/project/Conv2D) shape:[80, 1, 1, 184], type:FLOAT32 RO 58880 bytes\n",
      "  T#68(MobilenetV3large/expanded_conv_9/expand/Conv2D) shape:[184, 1, 1, 80], type:FLOAT32 RO 58880 bytes\n",
      "  T#69(MobilenetV3large/expanded_conv_9/project/Conv2D) shape:[80, 1, 1, 184], type:FLOAT32 RO 58880 bytes\n",
      "  T#70(MobilenetV3large/expanded_conv_10/expand/Conv2D) shape:[480, 1, 1, 80], type:FLOAT32 RO 153600 bytes\n",
      "  T#71(MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D) shape:[120, 1, 1, 480], type:FLOAT32 RO 230400 bytes\n",
      "  T#72(MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/Conv2D) shape:[480, 1, 1, 120], type:FLOAT32 RO 230400 bytes\n",
      "  T#73(MobilenetV3large/expanded_conv_10/project/Conv2D) shape:[112, 1, 1, 480], type:FLOAT32 RO 215040 bytes\n",
      "  T#74(MobilenetV3large/expanded_conv_11/expand/Conv2D) shape:[672, 1, 1, 112], type:FLOAT32 RO 301056 bytes\n",
      "  T#75(MobilenetV3large/expanded_conv_11/squeeze_excite/Conv/Conv2D) shape:[168, 1, 1, 672], type:FLOAT32 RO 451584 bytes\n",
      "  T#76(MobilenetV3large/expanded_conv_11/squeeze_excite/Conv_1/Conv2D) shape:[672, 1, 1, 168], type:FLOAT32 RO 451584 bytes\n",
      "  T#77(MobilenetV3large/expanded_conv_11/project/Conv2D) shape:[112, 1, 1, 672], type:FLOAT32 RO 301056 bytes\n",
      "  T#78(MobilenetV3large/expanded_conv_12/expand/Conv2D) shape:[672, 1, 1, 112], type:FLOAT32 RO 301056 bytes\n",
      "  T#79(MobilenetV3large/expanded_conv_12/squeeze_excite/Conv/Conv2D) shape:[168, 1, 1, 672], type:FLOAT32 RO 451584 bytes\n",
      "  T#80(MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D) shape:[672, 1, 1, 168], type:FLOAT32 RO 451584 bytes\n",
      "  T#81(MobilenetV3large/expanded_conv_12/project/Conv2D) shape:[160, 1, 1, 672], type:FLOAT32 RO 430080 bytes\n",
      "  T#82(MobilenetV3large/expanded_conv_13/expand/Conv2D) shape:[960, 1, 1, 160], type:FLOAT32 RO 614400 bytes\n",
      "  T#83(MobilenetV3large/expanded_conv_13/squeeze_excite/Conv/Conv2D) shape:[240, 1, 1, 960], type:FLOAT32 RO 921600 bytes\n",
      "  T#84(MobilenetV3large/expanded_conv_13/squeeze_excite/Conv_1/Conv2D) shape:[960, 1, 1, 240], type:FLOAT32 RO 921600 bytes\n",
      "  T#85(MobilenetV3large/expanded_conv_13/project/Conv2D) shape:[160, 1, 1, 960], type:FLOAT32 RO 614400 bytes\n",
      "  T#86(MobilenetV3large/expanded_conv_14/expand/Conv2D) shape:[960, 1, 1, 160], type:FLOAT32 RO 614400 bytes\n",
      "  T#87(MobilenetV3large/expanded_conv_14/squeeze_excite/Conv/Conv2D) shape:[240, 1, 1, 960], type:FLOAT32 RO 921600 bytes\n",
      "  T#88(MobilenetV3large/expanded_conv_14/squeeze_excite/Conv_1/Conv2D) shape:[960, 1, 1, 240], type:FLOAT32 RO 921600 bytes\n",
      "  T#89(MobilenetV3large/expanded_conv_14/project/Conv2D) shape:[160, 1, 1, 960], type:FLOAT32 RO 614400 bytes\n",
      "  T#90(MobilenetV3large/Conv_1/Conv2D) shape:[960, 1, 1, 160], type:FLOAT32 RO 614400 bytes\n",
      "  T#91(MobilenetV3large/Conv_2/Conv2D) shape:[1280, 1, 1, 960], type:FLOAT32 RO 4915200 bytes\n",
      "  T#92(MobilenetV3large/Logits/Conv2D) shape:[1000, 1, 1, 1280], type:FLOAT32 RO 5120000 bytes\n",
      "  T#93(MobilenetV3large/Conv/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv/project/Conv2D;MobilenetV3large/Conv/Conv2D) shape:[16], type:FLOAT32 RO 64 bytes\n",
      "  T#94(MobilenetV3large/expanded_conv/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv/depthwise/depthwise;MobilenetV3large/expanded_conv/project/Conv2D) shape:[1, 3, 3, 16], type:FLOAT32 RO 576 bytes\n",
      "  T#95(MobilenetV3large/expanded_conv/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv/project/Conv2D) shape:[16], type:FLOAT32 RO 64 bytes\n",
      "  T#96(MobilenetV3large/expanded_conv_1/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_1/depthwise/depthwise) shape:[1, 3, 3, 64], type:FLOAT32 RO 2304 bytes\n",
      "  T#97(MobilenetV3large/expanded_conv_1/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_1/project/Conv2D) shape:[24], type:FLOAT32 RO 96 bytes\n",
      "  T#98(MobilenetV3large/expanded_conv_2/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_2/depthwise/depthwise;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D) shape:[1, 3, 3, 72], type:FLOAT32 RO 2592 bytes\n",
      "  T#99(MobilenetV3large/expanded_conv_2/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_2/project/Conv2D) shape:[24], type:FLOAT32 RO 96 bytes\n",
      "  T#100(MobilenetV3large/expanded_conv_3/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/depthwise/depthwise;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D) shape:[1, 5, 5, 72], type:FLOAT32 RO 7200 bytes\n",
      "  T#101(MobilenetV3large/expanded_conv_3/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/project/Conv2D;MobilenetV3large/expanded_conv_3/project/Conv2D) shape:[40], type:FLOAT32 RO 160 bytes\n",
      "  T#102(MobilenetV3large/expanded_conv_4/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_4/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D) shape:[1, 5, 5, 120], type:FLOAT32 RO 12000 bytes\n",
      "  T#103(MobilenetV3large/expanded_conv_4/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/project/Conv2D;MobilenetV3large/expanded_conv_4/project/Conv2D) shape:[40], type:FLOAT32 RO 160 bytes\n",
      "  T#104(MobilenetV3large/expanded_conv_5/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D) shape:[1, 5, 5, 120], type:FLOAT32 RO 12000 bytes\n",
      "  T#105(MobilenetV3large/expanded_conv_5/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/project/Conv2D) shape:[40], type:FLOAT32 RO 160 bytes\n",
      "  T#106(MobilenetV3large/expanded_conv_6/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_6/expand/Conv2D) shape:[240], type:FLOAT32 RO 960 bytes\n",
      "  T#107(MobilenetV3large/expanded_conv_6/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_6/depthwise/depthwise;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv/Conv2D) shape:[1, 3, 3, 240], type:FLOAT32 RO 8640 bytes\n",
      "  T#108(MobilenetV3large/expanded_conv_6/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/project/Conv2D;MobilenetV3large/expanded_conv_6/project/Conv2D) shape:[80], type:FLOAT32 RO 320 bytes\n",
      "  T#109(MobilenetV3large/expanded_conv_7/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_7/depthwise/depthwise;MobilenetV3large/expanded_conv_7/expand/Conv2D) shape:[200], type:FLOAT32 RO 800 bytes\n",
      "  T#110(MobilenetV3large/expanded_conv_7/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_7/depthwise/depthwise) shape:[1, 3, 3, 200], type:FLOAT32 RO 7200 bytes\n",
      "  T#111(MobilenetV3large/expanded_conv_7/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/project/Conv2D;MobilenetV3large/expanded_conv_7/project/Conv2D) shape:[80], type:FLOAT32 RO 320 bytes\n",
      "  T#112(MobilenetV3large/expanded_conv_8/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/depthwise/depthwise;MobilenetV3large/expanded_conv_8/expand/Conv2D) shape:[184], type:FLOAT32 RO 736 bytes\n",
      "  T#113(MobilenetV3large/expanded_conv_8/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_8/depthwise/depthwise;MobilenetV3large/expanded_conv_9/depthwise/depthwise) shape:[1, 3, 3, 184], type:FLOAT32 RO 6624 bytes\n",
      "  T#114(MobilenetV3large/expanded_conv_8/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/project/Conv2D;MobilenetV3large/expanded_conv_8/project/Conv2D) shape:[80], type:FLOAT32 RO 320 bytes\n",
      "  T#115(MobilenetV3large/expanded_conv_9/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/depthwise/depthwise;MobilenetV3large/expanded_conv_9/expand/Conv2D) shape:[184], type:FLOAT32 RO 736 bytes\n",
      "  T#116(MobilenetV3large/expanded_conv_9/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/depthwise/depthwise) shape:[1, 3, 3, 184], type:FLOAT32 RO 6624 bytes\n",
      "  T#117(MobilenetV3large/expanded_conv_9/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/project/Conv2D) shape:[80], type:FLOAT32 RO 320 bytes\n",
      "  T#118(MobilenetV3large/expanded_conv_10/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_10/expand/Conv2D) shape:[480], type:FLOAT32 RO 1920 bytes\n",
      "  T#119(MobilenetV3large/expanded_conv_10/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_10/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/Conv2D) shape:[1, 3, 3, 480], type:FLOAT32 RO 17280 bytes\n",
      "  T#120(MobilenetV3large/expanded_conv_10/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_11/project/Conv2D;MobilenetV3large/expanded_conv_10/project/Conv2D) shape:[112], type:FLOAT32 RO 448 bytes\n",
      "  T#121(MobilenetV3large/expanded_conv_11/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_11/expand/Conv2D) shape:[672], type:FLOAT32 RO 2688 bytes\n",
      "  T#122(MobilenetV3large/expanded_conv_11/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_11/depthwise/depthwise;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D) shape:[1, 3, 3, 672], type:FLOAT32 RO 24192 bytes\n",
      "  T#123(MobilenetV3large/expanded_conv_11/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_11/project/Conv2D) shape:[112], type:FLOAT32 RO 448 bytes\n",
      "  T#124(MobilenetV3large/expanded_conv_12/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_12/expand/Conv2D) shape:[672], type:FLOAT32 RO 2688 bytes\n",
      "  T#125(MobilenetV3large/expanded_conv_12/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_12/depthwise/depthwise;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D) shape:[1, 5, 5, 672], type:FLOAT32 RO 67200 bytes\n",
      "  T#126(MobilenetV3large/expanded_conv_12/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/project/Conv2D;MobilenetV3large/expanded_conv_12/project/Conv2D) shape:[160], type:FLOAT32 RO 640 bytes\n",
      "  T#127(MobilenetV3large/expanded_conv_13/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_13/expand/Conv2D) shape:[960], type:FLOAT32 RO 3840 bytes\n",
      "  T#128(MobilenetV3large/expanded_conv_13/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_13/depthwise/depthwise;MobilenetV3large/Conv_1/Conv2D) shape:[1, 5, 5, 960], type:FLOAT32 RO 96000 bytes\n",
      "  T#129(MobilenetV3large/expanded_conv_13/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/project/Conv2D;MobilenetV3large/expanded_conv_13/project/Conv2D) shape:[160], type:FLOAT32 RO 640 bytes\n",
      "  T#130(MobilenetV3large/expanded_conv_14/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_14/expand/Conv2D) shape:[960], type:FLOAT32 RO 3840 bytes\n",
      "  T#131(MobilenetV3large/expanded_conv_14/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/depthwise/depthwise;MobilenetV3large/Conv_1/Conv2D) shape:[1, 5, 5, 960], type:FLOAT32 RO 96000 bytes\n",
      "  T#132(MobilenetV3large/expanded_conv_14/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/project/Conv2D) shape:[160], type:FLOAT32 RO 640 bytes\n",
      "  T#133(MobilenetV3large/Conv_1/BatchNorm/FusedBatchNormV3;MobilenetV3large/Conv_1/Conv2D) shape:[960], type:FLOAT32 RO 3840 bytes\n",
      "  T#134(MobilenetV3large/Conv_2/BiasAdd;MobilenetV3large/Conv_2/Conv2D;Conv_2/bias) shape:[1280], type:FLOAT32 RO 5120 bytes\n",
      "  T#135(MobilenetV3large/Logits/BiasAdd;MobilenetV3large/Logits/Conv2D;Logits/bias) shape:[1000], type:FLOAT32 RO 4000 bytes\n",
      "  T#136(MobilenetV3large/rescaling/mul) shape_signature:[-1, -1, -1, 3], type:FLOAT32\n",
      "  T#137(MobilenetV3large/rescaling/add) shape_signature:[-1, -1, -1, 3], type:FLOAT32\n",
      "  T#138(MobilenetV3large/Conv/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv/project/Conv2D;MobilenetV3large/Conv/Conv2D1) shape_signature:[-1, -1, -1, 16], type:FLOAT32\n",
      "  T#139(MobilenetV3large/multiply/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu/Relu6;MobilenetV3large/tf.__operators__.add/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply/Mul) shape_signature:[-1, -1, -1, 16], type:FLOAT32\n",
      "  T#140(MobilenetV3large/re_lu_1/Relu;MobilenetV3large/expanded_conv/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv/depthwise/depthwise;MobilenetV3large/expanded_conv/project/Conv2D) shape_signature:[-1, -1, -1, 16], type:FLOAT32\n",
      "  T#141(MobilenetV3large/expanded_conv/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv/project/Conv2D1) shape_signature:[-1, -1, -1, 16], type:FLOAT32\n",
      "  T#142(MobilenetV3large/expanded_conv/Add/add) shape_signature:[-1, -1, -1, 16], type:FLOAT32\n",
      "  T#143(MobilenetV3large/re_lu_2/Relu;MobilenetV3large/expanded_conv_1/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_1/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_1/depthwise/depthwise;MobilenetV3large/expanded_conv_1/expand/Conv2D) shape_signature:[-1, -1, -1, 64], type:FLOAT32\n",
      "  T#144(MobilenetV3large/expanded_conv_1/depthwise/pad/Pad) shape_signature:[-1, -1, -1, 64], type:FLOAT32\n",
      "  T#145(MobilenetV3large/re_lu_3/Relu;MobilenetV3large/expanded_conv_1/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_1/depthwise/depthwise) shape_signature:[-1, -1, -1, 64], type:FLOAT32\n",
      "  T#146(MobilenetV3large/expanded_conv_1/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_1/project/Conv2D1) shape_signature:[-1, -1, -1, 24], type:FLOAT32\n",
      "  T#147(MobilenetV3large/re_lu_4/Relu;MobilenetV3large/expanded_conv_2/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/depthwise/depthwise;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_2/expand/Conv2D) shape_signature:[-1, -1, -1, 72], type:FLOAT32\n",
      "  T#148(MobilenetV3large/re_lu_5/Relu;MobilenetV3large/expanded_conv_2/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/depthwise/depthwise;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_2/depthwise/depthwise) shape_signature:[-1, -1, -1, 72], type:FLOAT32\n",
      "  T#149(MobilenetV3large/expanded_conv_2/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_2/project/Conv2D1) shape_signature:[-1, -1, -1, 24], type:FLOAT32\n",
      "  T#150(MobilenetV3large/expanded_conv_2/Add/add) shape_signature:[-1, -1, -1, 24], type:FLOAT32\n",
      "  T#151(MobilenetV3large/re_lu_6/Relu;MobilenetV3large/expanded_conv_3/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/depthwise/depthwise;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_3/expand/Conv2D) shape_signature:[-1, -1, -1, 72], type:FLOAT32\n",
      "  T#152(MobilenetV3large/expanded_conv_3/depthwise/pad/Pad) shape_signature:[-1, -1, -1, 72], type:FLOAT32\n",
      "  T#153(MobilenetV3large/re_lu_7/Relu;MobilenetV3large/expanded_conv_3/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/depthwise/depthwise;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D) shape_signature:[-1, -1, -1, 72], type:FLOAT32\n",
      "  T#154(MobilenetV3large/expanded_conv_3/squeeze_excite/AvgPool/Mean) shape_signature:[-1, 1, 1, 72], type:FLOAT32\n",
      "  T#155(MobilenetV3large/expanded_conv_3/squeeze_excite/Relu/Relu;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv/BiasAdd;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv/Conv2D;expanded_conv_3/squeeze_excite/Conv/bias) shape_signature:[-1, 1, 1, 24], type:FLOAT32\n",
      "  T#156(MobilenetV3large/re_lu_8/Relu6;MobilenetV3large/tf.__operators__.add_1/AddV2;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D;expanded_conv_3/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y1) shape_signature:[-1, 1, 1, 72], type:FLOAT32\n",
      "  T#157(MobilenetV3large/tf.math.multiply_1/Mul) shape_signature:[-1, 1, 1, 72], type:FLOAT32\n",
      "  T#158(MobilenetV3large/expanded_conv_3/squeeze_excite/Mul/mul) shape_signature:[-1, -1, -1, 72], type:FLOAT32\n",
      "  T#159(MobilenetV3large/expanded_conv_3/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/project/Conv2D;MobilenetV3large/expanded_conv_3/project/Conv2D1) shape_signature:[-1, -1, -1, 40], type:FLOAT32\n",
      "  T#160(MobilenetV3large/re_lu_9/Relu;MobilenetV3large/expanded_conv_4/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_4/expand/Conv2D) shape_signature:[-1, -1, -1, 120], type:FLOAT32\n",
      "  T#161(MobilenetV3large/re_lu_10/Relu;MobilenetV3large/expanded_conv_4/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_4/depthwise/depthwise) shape_signature:[-1, -1, -1, 120], type:FLOAT32\n",
      "  T#162(MobilenetV3large/expanded_conv_4/squeeze_excite/AvgPool/Mean) shape_signature:[-1, 1, 1, 120], type:FLOAT32\n",
      "  T#163(MobilenetV3large/expanded_conv_4/squeeze_excite/Relu/Relu;MobilenetV3large/expanded_conv_4/squeeze_excite/Conv/BiasAdd;MobilenetV3large/expanded_conv_5/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_4/squeeze_excite/Conv/Conv2D;expanded_conv_4/squeeze_excite/Conv/bias) shape_signature:[-1, 1, 1, 32], type:FLOAT32\n",
      "  T#164(MobilenetV3large/re_lu_11/Relu6;MobilenetV3large/tf.__operators__.add_2/AddV2;MobilenetV3large/expanded_conv_4/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_4/squeeze_excite/Conv_1/Conv2D;expanded_conv_4/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y1) shape_signature:[-1, 1, 1, 120], type:FLOAT32\n",
      "  T#165(MobilenetV3large/tf.math.multiply_2/Mul) shape_signature:[-1, 1, 1, 120], type:FLOAT32\n",
      "  T#166(MobilenetV3large/expanded_conv_4/squeeze_excite/Mul/mul) shape_signature:[-1, -1, -1, 120], type:FLOAT32\n",
      "  T#167(MobilenetV3large/expanded_conv_4/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/project/Conv2D;MobilenetV3large/expanded_conv_4/project/Conv2D1) shape_signature:[-1, -1, -1, 40], type:FLOAT32\n",
      "  T#168(MobilenetV3large/expanded_conv_4/Add/add) shape_signature:[-1, -1, -1, 40], type:FLOAT32\n",
      "  T#169(MobilenetV3large/re_lu_12/Relu;MobilenetV3large/expanded_conv_5/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_5/expand/Conv2D) shape_signature:[-1, -1, -1, 120], type:FLOAT32\n",
      "  T#170(MobilenetV3large/re_lu_13/Relu;MobilenetV3large/expanded_conv_5/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D) shape_signature:[-1, -1, -1, 120], type:FLOAT32\n",
      "  T#171(MobilenetV3large/expanded_conv_5/squeeze_excite/AvgPool/Mean) shape_signature:[-1, 1, 1, 120], type:FLOAT32\n",
      "  T#172(MobilenetV3large/expanded_conv_5/squeeze_excite/Relu/Relu;MobilenetV3large/expanded_conv_5/squeeze_excite/Conv/BiasAdd;MobilenetV3large/expanded_conv_5/squeeze_excite/Conv/Conv2D;expanded_conv_5/squeeze_excite/Conv/bias) shape_signature:[-1, 1, 1, 32], type:FLOAT32\n",
      "  T#173(MobilenetV3large/re_lu_14/Relu6;MobilenetV3large/tf.__operators__.add_3/AddV2;MobilenetV3large/expanded_conv_5/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_5/squeeze_excite/Conv_1/Conv2D;expanded_conv_5/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y1) shape_signature:[-1, 1, 1, 120], type:FLOAT32\n",
      "  T#174(MobilenetV3large/tf.math.multiply_3/Mul) shape_signature:[-1, 1, 1, 120], type:FLOAT32\n",
      "  T#175(MobilenetV3large/expanded_conv_5/squeeze_excite/Mul/mul) shape_signature:[-1, -1, -1, 120], type:FLOAT32\n",
      "  T#176(MobilenetV3large/expanded_conv_5/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/project/Conv2D1) shape_signature:[-1, -1, -1, 40], type:FLOAT32\n",
      "  T#177(MobilenetV3large/expanded_conv_5/Add/add) shape_signature:[-1, -1, -1, 40], type:FLOAT32\n",
      "  T#178(MobilenetV3large/expanded_conv_6/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_6/expand/Conv2D1) shape_signature:[-1, -1, -1, 240], type:FLOAT32\n",
      "  T#179(MobilenetV3large/multiply_1/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_15/Relu6;MobilenetV3large/tf.__operators__.add_4/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_4/Mul) shape_signature:[-1, -1, -1, 240], type:FLOAT32\n",
      "  T#180(MobilenetV3large/expanded_conv_6/depthwise/pad/Pad) shape_signature:[-1, -1, -1, 240], type:FLOAT32\n",
      "  T#181(MobilenetV3large/expanded_conv_6/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_6/depthwise/depthwise;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv/Conv2D1) shape_signature:[-1, -1, -1, 240], type:FLOAT32\n",
      "  T#182(MobilenetV3large/multiply_2/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_16/Relu6;MobilenetV3large/tf.__operators__.add_5/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_5/Mul) shape_signature:[-1, -1, -1, 240], type:FLOAT32\n",
      "  T#183(MobilenetV3large/expanded_conv_6/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/project/Conv2D;MobilenetV3large/expanded_conv_6/project/Conv2D1) shape_signature:[-1, -1, -1, 80], type:FLOAT32\n",
      "  T#184(MobilenetV3large/expanded_conv_7/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_7/depthwise/depthwise;MobilenetV3large/expanded_conv_7/expand/Conv2D1) shape_signature:[-1, -1, -1, 200], type:FLOAT32\n",
      "  T#185(MobilenetV3large/multiply_3/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_17/Relu6;MobilenetV3large/tf.__operators__.add_6/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_6/Mul) shape_signature:[-1, -1, -1, 200], type:FLOAT32\n",
      "  T#186(MobilenetV3large/expanded_conv_7/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_7/depthwise/depthwise1) shape_signature:[-1, -1, -1, 200], type:FLOAT32\n",
      "  T#187(MobilenetV3large/multiply_4/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_18/Relu6;MobilenetV3large/tf.__operators__.add_7/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_7/Mul) shape_signature:[-1, -1, -1, 200], type:FLOAT32\n",
      "  T#188(MobilenetV3large/expanded_conv_7/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/project/Conv2D;MobilenetV3large/expanded_conv_7/project/Conv2D1) shape_signature:[-1, -1, -1, 80], type:FLOAT32\n",
      "  T#189(MobilenetV3large/expanded_conv_7/Add/add) shape_signature:[-1, -1, -1, 80], type:FLOAT32\n",
      "  T#190(MobilenetV3large/expanded_conv_8/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/depthwise/depthwise;MobilenetV3large/expanded_conv_8/expand/Conv2D1) shape_signature:[-1, -1, -1, 184], type:FLOAT32\n",
      "  T#191(MobilenetV3large/multiply_5/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_19/Relu6;MobilenetV3large/tf.__operators__.add_8/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_8/Mul) shape_signature:[-1, -1, -1, 184], type:FLOAT32\n",
      "  T#192(MobilenetV3large/expanded_conv_8/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/depthwise/depthwise;MobilenetV3large/expanded_conv_8/depthwise/depthwise) shape_signature:[-1, -1, -1, 184], type:FLOAT32\n",
      "  T#193(MobilenetV3large/multiply_6/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_20/Relu6;MobilenetV3large/tf.__operators__.add_9/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_9/Mul) shape_signature:[-1, -1, -1, 184], type:FLOAT32\n",
      "  T#194(MobilenetV3large/expanded_conv_8/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/project/Conv2D;MobilenetV3large/expanded_conv_8/project/Conv2D1) shape_signature:[-1, -1, -1, 80], type:FLOAT32\n",
      "  T#195(MobilenetV3large/expanded_conv_8/Add/add) shape_signature:[-1, -1, -1, 80], type:FLOAT32\n",
      "  T#196(MobilenetV3large/expanded_conv_9/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/depthwise/depthwise;MobilenetV3large/expanded_conv_9/expand/Conv2D1) shape_signature:[-1, -1, -1, 184], type:FLOAT32\n",
      "  T#197(MobilenetV3large/multiply_7/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_21/Relu6;MobilenetV3large/tf.__operators__.add_10/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_10/Mul) shape_signature:[-1, -1, -1, 184], type:FLOAT32\n",
      "  T#198(MobilenetV3large/expanded_conv_9/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/depthwise/depthwise1) shape_signature:[-1, -1, -1, 184], type:FLOAT32\n",
      "  T#199(MobilenetV3large/multiply_8/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_22/Relu6;MobilenetV3large/tf.__operators__.add_11/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_11/Mul) shape_signature:[-1, -1, -1, 184], type:FLOAT32\n",
      "  T#200(MobilenetV3large/expanded_conv_9/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/project/Conv2D1) shape_signature:[-1, -1, -1, 80], type:FLOAT32\n",
      "  T#201(MobilenetV3large/expanded_conv_9/Add/add) shape_signature:[-1, -1, -1, 80], type:FLOAT32\n",
      "  T#202(MobilenetV3large/expanded_conv_10/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_10/expand/Conv2D1) shape_signature:[-1, -1, -1, 480], type:FLOAT32\n",
      "  T#203(MobilenetV3large/multiply_9/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_23/Relu6;MobilenetV3large/tf.__operators__.add_12/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_12/Mul) shape_signature:[-1, -1, -1, 480], type:FLOAT32\n",
      "  T#204(MobilenetV3large/expanded_conv_10/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_10/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/Conv2D1) shape_signature:[-1, -1, -1, 480], type:FLOAT32\n",
      "  T#205(MobilenetV3large/multiply_10/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_24/Relu6;MobilenetV3large/tf.__operators__.add_13/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_13/Mul) shape_signature:[-1, -1, -1, 480], type:FLOAT32\n",
      "  T#206(MobilenetV3large/expanded_conv_10/squeeze_excite/AvgPool/Mean) shape_signature:[-1, 1, 1, 480], type:FLOAT32\n",
      "  T#207(MobilenetV3large/expanded_conv_10/squeeze_excite/Relu/Relu;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/BiasAdd;MobilenetV3large/expanded_conv_5/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D;expanded_conv_10/squeeze_excite/Conv/bias) shape_signature:[-1, 1, 1, 120], type:FLOAT32\n",
      "  T#208(MobilenetV3large/re_lu_25/Relu6;MobilenetV3large/tf.__operators__.add_14/AddV2;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/Conv2D;expanded_conv_10/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y1) shape_signature:[-1, 1, 1, 480], type:FLOAT32\n",
      "  T#209(MobilenetV3large/tf.math.multiply_14/Mul) shape_signature:[-1, 1, 1, 480], type:FLOAT32\n",
      "  T#210(MobilenetV3large/expanded_conv_10/squeeze_excite/Mul/mul) shape_signature:[-1, -1, -1, 480], type:FLOAT32\n",
      "  T#211(MobilenetV3large/expanded_conv_10/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_11/project/Conv2D;MobilenetV3large/expanded_conv_10/project/Conv2D1) shape_signature:[-1, -1, -1, 112], type:FLOAT32\n",
      "  T#212(MobilenetV3large/expanded_conv_11/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_11/expand/Conv2D1) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
      "  T#213(MobilenetV3large/multiply_11/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_26/Relu6;MobilenetV3large/tf.__operators__.add_15/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_15/Mul) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
      "  T#214(MobilenetV3large/expanded_conv_11/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_11/depthwise/depthwise;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D1) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
      "  T#215(MobilenetV3large/multiply_12/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_27/Relu6;MobilenetV3large/tf.__operators__.add_16/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_16/Mul) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
      "  T#216(MobilenetV3large/expanded_conv_11/squeeze_excite/AvgPool/Mean) shape_signature:[-1, 1, 1, 672], type:FLOAT32\n",
      "  T#217(MobilenetV3large/expanded_conv_11/squeeze_excite/Relu/Relu;MobilenetV3large/expanded_conv_11/squeeze_excite/Conv/BiasAdd;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_11/squeeze_excite/Conv/Conv2D;expanded_conv_11/squeeze_excite/Conv/bias) shape_signature:[-1, 1, 1, 168], type:FLOAT32\n",
      "  T#218(MobilenetV3large/re_lu_28/Relu6;MobilenetV3large/tf.__operators__.add_17/AddV2;MobilenetV3large/expanded_conv_11/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_11/squeeze_excite/Conv_1/Conv2D;expanded_conv_11/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y1) shape_signature:[-1, 1, 1, 672], type:FLOAT32\n",
      "  T#219(MobilenetV3large/tf.math.multiply_17/Mul) shape_signature:[-1, 1, 1, 672], type:FLOAT32\n",
      "  T#220(MobilenetV3large/expanded_conv_11/squeeze_excite/Mul/mul) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
      "  T#221(MobilenetV3large/expanded_conv_11/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_11/project/Conv2D1) shape_signature:[-1, -1, -1, 112], type:FLOAT32\n",
      "  T#222(MobilenetV3large/expanded_conv_11/Add/add) shape_signature:[-1, -1, -1, 112], type:FLOAT32\n",
      "  T#223(MobilenetV3large/expanded_conv_12/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_12/expand/Conv2D1) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
      "  T#224(MobilenetV3large/multiply_13/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_29/Relu6;MobilenetV3large/tf.__operators__.add_18/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_18/Mul) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
      "  T#225(MobilenetV3large/expanded_conv_12/depthwise/pad/Pad) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
      "  T#226(MobilenetV3large/expanded_conv_12/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_12/depthwise/depthwise;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D1) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
      "  T#227(MobilenetV3large/multiply_14/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_30/Relu6;MobilenetV3large/tf.__operators__.add_19/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_19/Mul) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
      "  T#228(MobilenetV3large/expanded_conv_12/squeeze_excite/AvgPool/Mean) shape_signature:[-1, 1, 1, 672], type:FLOAT32\n",
      "  T#229(MobilenetV3large/expanded_conv_12/squeeze_excite/Relu/Relu;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv/BiasAdd;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv/Conv2D;expanded_conv_12/squeeze_excite/Conv/bias) shape_signature:[-1, 1, 1, 168], type:FLOAT32\n",
      "  T#230(MobilenetV3large/re_lu_31/Relu6;MobilenetV3large/tf.__operators__.add_20/AddV2;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D;expanded_conv_12/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y1) shape_signature:[-1, 1, 1, 672], type:FLOAT32\n",
      "  T#231(MobilenetV3large/tf.math.multiply_20/Mul) shape_signature:[-1, 1, 1, 672], type:FLOAT32\n",
      "  T#232(MobilenetV3large/expanded_conv_12/squeeze_excite/Mul/mul) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
      "  T#233(MobilenetV3large/expanded_conv_12/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/project/Conv2D;MobilenetV3large/expanded_conv_12/project/Conv2D1) shape_signature:[-1, -1, -1, 160], type:FLOAT32\n",
      "  T#234(MobilenetV3large/expanded_conv_13/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_13/expand/Conv2D1) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
      "  T#235(MobilenetV3large/multiply_15/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_32/Relu6;MobilenetV3large/tf.__operators__.add_21/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_21/Mul) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
      "  T#236(MobilenetV3large/expanded_conv_13/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/depthwise/depthwise;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_13/depthwise/depthwise) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
      "  T#237(MobilenetV3large/multiply_16/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_33/Relu6;MobilenetV3large/tf.__operators__.add_22/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_22/Mul) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
      "  T#238(MobilenetV3large/expanded_conv_13/squeeze_excite/AvgPool/Mean) shape_signature:[-1, 1, 1, 960], type:FLOAT32\n",
      "  T#239(MobilenetV3large/expanded_conv_13/squeeze_excite/Relu/Relu;MobilenetV3large/expanded_conv_13/squeeze_excite/Conv/BiasAdd;MobilenetV3large/expanded_conv_6/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_6/depthwise/depthwise;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_13/squeeze_excite/Conv/Conv2D;expanded_conv_13/squeeze_excite/Conv/bias) shape_signature:[-1, 1, 1, 240], type:FLOAT32\n",
      "  T#240(MobilenetV3large/re_lu_34/Relu6;MobilenetV3large/tf.__operators__.add_23/AddV2;MobilenetV3large/expanded_conv_13/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_13/squeeze_excite/Conv_1/Conv2D;expanded_conv_13/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y1) shape_signature:[-1, 1, 1, 960], type:FLOAT32\n",
      "  T#241(MobilenetV3large/tf.math.multiply_23/Mul) shape_signature:[-1, 1, 1, 960], type:FLOAT32\n",
      "  T#242(MobilenetV3large/expanded_conv_13/squeeze_excite/Mul/mul) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
      "  T#243(MobilenetV3large/expanded_conv_13/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/project/Conv2D;MobilenetV3large/expanded_conv_13/project/Conv2D1) shape_signature:[-1, -1, -1, 160], type:FLOAT32\n",
      "  T#244(MobilenetV3large/expanded_conv_13/Add/add) shape_signature:[-1, -1, -1, 160], type:FLOAT32\n",
      "  T#245(MobilenetV3large/expanded_conv_14/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_14/expand/Conv2D1) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
      "  T#246(MobilenetV3large/multiply_17/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_35/Relu6;MobilenetV3large/tf.__operators__.add_24/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_24/Mul) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
      "  T#247(MobilenetV3large/expanded_conv_14/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/depthwise/depthwise;MobilenetV3large/Conv_1/Conv2D1) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
      "  T#248(MobilenetV3large/multiply_18/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_36/Relu6;MobilenetV3large/tf.__operators__.add_25/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_25/Mul) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
      "  T#249(MobilenetV3large/expanded_conv_14/squeeze_excite/AvgPool/Mean) shape_signature:[-1, 1, 1, 960], type:FLOAT32\n",
      "  T#250(MobilenetV3large/expanded_conv_14/squeeze_excite/Relu/Relu;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv/BiasAdd;MobilenetV3large/expanded_conv_6/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_6/depthwise/depthwise;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv/Conv2D;expanded_conv_14/squeeze_excite/Conv/bias) shape_signature:[-1, 1, 1, 240], type:FLOAT32\n",
      "  T#251(MobilenetV3large/re_lu_37/Relu6;MobilenetV3large/tf.__operators__.add_26/AddV2;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv_1/Conv2D;expanded_conv_14/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y1) shape_signature:[-1, 1, 1, 960], type:FLOAT32\n",
      "  T#252(MobilenetV3large/tf.math.multiply_26/Mul) shape_signature:[-1, 1, 1, 960], type:FLOAT32\n",
      "  T#253(MobilenetV3large/expanded_conv_14/squeeze_excite/Mul/mul) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
      "  T#254(MobilenetV3large/expanded_conv_14/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/project/Conv2D1) shape_signature:[-1, -1, -1, 160], type:FLOAT32\n",
      "  T#255(MobilenetV3large/expanded_conv_14/Add/add) shape_signature:[-1, -1, -1, 160], type:FLOAT32\n",
      "  T#256(MobilenetV3large/Conv_1/BatchNorm/FusedBatchNormV3;MobilenetV3large/Conv_1/Conv2D1) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
      "  T#257(MobilenetV3large/multiply_19/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_38/Relu6;MobilenetV3large/tf.__operators__.add_27/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_27/Mul) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
      "  T#258(MobilenetV3large/global_average_pooling2d/Mean) shape_signature:[-1, 1, 1, 960], type:FLOAT32\n",
      "  T#259(MobilenetV3large/Conv_2/BiasAdd;MobilenetV3large/Conv_2/Conv2D;Conv_2/bias1) shape_signature:[-1, 1, 1, 1280], type:FLOAT32\n",
      "  T#260(MobilenetV3large/multiply_20/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_39/Relu6;MobilenetV3large/tf.__operators__.add_28/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_28/Mul) shape_signature:[-1, 1, 1, 1280], type:FLOAT32\n",
      "  T#261(MobilenetV3large/Logits/BiasAdd;MobilenetV3large/Logits/Conv2D;Logits/bias1) shape_signature:[-1, 1, 1, 1000], type:FLOAT32\n",
      "  T#262(MobilenetV3large/flatten_1/Reshape) shape_signature:[-1, 1000], type:FLOAT32\n",
      "  T#263(StatefulPartitionedCall:0) shape_signature:[-1, 1000], type:FLOAT32\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Your TFLite model has ‘1’ signature_def(s).\n",
      "\n",
      "Signature#0 key: 'serving_default'\n",
      "- Subgraph: Subgraph#0\n",
      "- Inputs: \n",
      "    'input_1' : T#0\n",
      "- Outputs: \n",
      "    'Predictions' : T#263\n",
      "\n",
      "---------------------------------------------------------------\n",
      "              Model size:   21944896 bytes\n",
      "    Non-data buffer size:      61460 bytes (00.28 %)\n",
      "  Total data buffer size:   21883436 bytes (99.72 %)\n",
      "    (Zero value buffers):          0 bytes (00.00 %)\n",
      "\n",
      "* Buffers of TFLite model are mostly used for constant tensors.\n",
      "  And zero value buffers are buffers filled with zeros.\n",
      "  Non-data buffers area are used to store operators, subgraphs and etc.\n",
      "  You can find more details from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.MobileNetV3Large()\n",
    "fb_model = tf.lite.TFLiteConverter.from_keras_model(model).convert()\n",
    "\n",
    "tf.lite.experimental.Analyzer.analyze(model_content=fb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BGqG2j9yqRf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Check GPU delegate compatibility\n",
    "\n",
    "The ModelAnalyzer API provides a way to check the [GPU delegate](https://www.tensorflow.org/lite/performance/gpu) compatibility of the given model by providing `gpu_compatibility=True` option.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVGC1oX33RkV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Case 1: When model is incompatibile\n",
    "\n",
    "The following code shows a way to use `gpu_compatibility=True` option for simple tf.function which uses `tf.slice` with a 2D tensor and `tf.cosh` which are not compatible with GPU delegate.\n",
    "\n",
    "You will see `GPU COMPATIBILITY WARNING` per every node which has compatibility issue(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9GEg5plIzD-3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TFLite ModelAnalyzer ===\n",
      "\n",
      "Your TFLite model has '1' subgraph(s). In the subgraph description below,\n",
      "T# represents the Tensor numbers. For example, in Subgraph#0, the FlexCosh op takes\n",
      "tensor #0 as input and produces tensor #2 as output.\n",
      "\n",
      "Subgraph#0 main(T#0) -> [T#4]\n",
      "  Op#0 FlexCosh(T#0) -> [T#2]\n",
      "GPU COMPATIBILITY WARNING: Not supported custom op FlexCosh\n",
      "  Op#1 SLICE(T#0, T#1, T#1) -> [T#3]\n",
      "GPU COMPATIBILITY WARNING: SLICE supports for 3 or 4 dimensional tensors only, but node has 2 dimensional tensors.\n",
      "  Op#2 ADD(T#2, T#3) -> [T#4]\n",
      "\n",
      "GPU COMPATIBILITY WARNING: Subgraph#0 has GPU delegate compatibility issues at nodes 0, 1 with TFLite runtime version 2.8.0\n",
      "\n",
      "Tensors of Subgraph#0\n",
      "  T#0(x) shape:[4, 4], type:FLOAT32\n",
      "  T#1(Slice/begin) shape:[2], type:INT32 RO 8 bytes\n",
      "  T#2(Cosh) shape:[4, 4], type:FLOAT32\n",
      "  T#3(Slice) shape:[1, 1], type:FLOAT32\n",
      "  T#4(Identity) shape:[4, 4], type:FLOAT32\n",
      "\n",
      "---------------------------------------------------------------\n",
      "              Model size:        944 bytes\n",
      "    Non-data buffer size:        920 bytes (97.46 %)\n",
      "  Total data buffer size:         24 bytes (02.54 %)\n",
      "    (Zero value buffers):          0 bytes (00.00 %)\n",
      "\n",
      "* Buffers of TFLite model are mostly used for constant tensors.\n",
      "  And zero value buffers are buffers filled with zeros.\n",
      "  Non-data buffers area are used to store operators, subgraphs and etc.\n",
      "  You can find more details from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "@tf.function(input_signature=[\n",
    "    tf.TensorSpec(shape=[4, 4], dtype=tf.float32)\n",
    "])\n",
    "def func(x):\n",
    "  return tf.cosh(x) + tf.slice(x, [1, 1], [1, 1])\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_concrete_functions(\n",
    "    [func.get_concrete_function()], func)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS,\n",
    "]\n",
    "fb_model = converter.convert()\n",
    "\n",
    "tf.lite.experimental.Analyzer.analyze(model_content=fb_model, gpu_compatibility=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFU7HYb_2a8M",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Case 2: When model is compatibile\n",
    "\n",
    "In this example, the given model is compatbile with GPU delegate.\n",
    "\n",
    "**Note:** Even though the tool doesn't find any compatibility issue, it doesn't guarantee that your model works well with GPU delegate on every device. There could be some runtime incompatibililty happen such as missing `CL_DEVICE_IMAGE_SUPPORT` feature by target OpenGL backend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\admin\\AppData\\Local\\Temp\\tmp0asuvbjn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\admin\\AppData\\Local\\Temp\\tmp0asuvbjn\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TFLite ModelAnalyzer ===\n",
      "\n",
      "Your TFLite model has '1' subgraph(s). In the subgraph description below,\n",
      "T# represents the Tensor numbers. For example, in Subgraph#0, the RESHAPE op takes\n",
      "tensor #0 and tensor #1 as input and produces tensor #4 as output.\n",
      "\n",
      "Subgraph#0 main(T#0) -> [T#6]\n",
      "  Op#0 RESHAPE(T#0, T#1) -> [T#4]\n",
      "  Op#1 FULLY_CONNECTED(T#4, T#2, T#-1) -> [T#5]\n",
      "  Op#2 FULLY_CONNECTED(T#5, T#3, T#-1) -> [T#6]\n",
      "\n",
      "Tensors of Subgraph#0\n",
      "  T#0(serving_default_flatten_2_input:0) shape_signature:[-1, 128, 128], type:FLOAT32\n",
      "  T#1(sequential_1/flatten_2/Const) shape:[2], type:INT32 RO 8 bytes\n",
      "  T#2(sequential_1/dense_2/MatMul) shape:[256, 16384], type:FLOAT32 RO 16777216 bytes\n",
      "  T#3(sequential_1/dense_3/MatMul) shape:[10, 256], type:FLOAT32 RO 10240 bytes\n",
      "  T#4(sequential_1/flatten_2/Reshape) shape_signature:[-1, 16384], type:FLOAT32\n",
      "  T#5(sequential_1/dense_2/MatMul;sequential_1/dense_2/Relu;sequential_1/dense_2/BiasAdd) shape_signature:[-1, 256], type:FLOAT32\n",
      "  T#6(StatefulPartitionedCall:0) shape_signature:[-1, 10], type:FLOAT32\n",
      "\n",
      "\n",
      "Your model looks compatibile with GPU delegate with TFLite runtime version 2.8.0.\n",
      "But it doesn't guarantee that your model works well with GPU delegate.\n",
      "There could be some runtime incompatibililty happen.\n",
      "---------------------------------------------------------------\n",
      "Your TFLite model has ‘1’ signature_def(s).\n",
      "\n",
      "Signature#0 key: 'serving_default'\n",
      "- Subgraph: Subgraph#0\n",
      "- Inputs: \n",
      "    'flatten_2_input' : T#0\n",
      "- Outputs: \n",
      "    'dense_3' : T#6\n",
      "\n",
      "---------------------------------------------------------------\n",
      "              Model size:   16788892 bytes\n",
      "    Non-data buffer size:       1412 bytes (00.01 %)\n",
      "  Total data buffer size:   16787480 bytes (99.99 %)\n",
      "    (Zero value buffers):          0 bytes (00.00 %)\n",
      "\n",
      "* Buffers of TFLite model are mostly used for constant tensors.\n",
      "  And zero value buffers are buffers filled with zeros.\n",
      "  Non-data buffers area are used to store operators, subgraphs and etc.\n",
      "  You can find more details from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(128, 128)),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "fb_model = tf.lite.TFLiteConverter.from_keras_model(model).convert()\n",
    "\n",
    "tf.lite.experimental.Analyzer.analyze(model_content=fb_model, gpu_compatibility=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model_analyzer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
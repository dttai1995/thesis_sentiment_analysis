{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-04 11:44:39 | INFO | fairseq.file_utils | loading archive file ..\\PhoBERT_base_fairseq\n",
      "2022-06-04 11:44:40 | INFO | fairseq.tasks.masked_lm | dictionary: 64000 types\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "# Load PhoBERT-base in fairseq\n",
    "from fairseq.models.roberta import RobertaModel\n",
    "\n",
    "phobert_base_folder = os.path.join(\"..\", \"PhoBERT_base_fairseq\")\n",
    "bpe_codes_file = os.path.join(phobert_base_folder , 'bpe.codes')\n",
    "phobert = RobertaModel.from_pretrained(phobert_base_folder, checkpoint_file='model.pt', bpe='fastbpe', bpe_codes=bpe_codes_file).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "line = \"Tôi là sinh_viên trường đại_học Công_nghệ .\"\n",
    "subwords = phobert.encode(line)\n",
    "\n",
    "last_layer_features = phobert.extract_features(subwords)\n",
    "assert last_layer_features.size() == torch.Size([1, 9, 768])\n",
    "\n",
    "\n",
    "all_layers = phobert.extract_features(subwords, return_all_hiddens=True)\n",
    "assert len(all_layers) == 13\n",
    "assert torch.all(all_layers[-1] == last_layer_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Tôi là sinh_viên trường Đại_học ngoại_thương .', 0.36145657300949097, 'Đại_học'), ('Tôi là sinh_viên trường ĐH ngoại_thương .', 0.291090726852417, 'ĐH'), ('Tôi là sinh_viên trường đại_học ngoại_thương .', 0.2378615140914917, 'đại_học'), ('Tôi là sinh_viên trường Kinh_tế ngoại_thương .', 0.030656956136226654, 'Kinh_tế'), ('Tôi là sinh_viên trường Quản_lý ngoại_thương .', 0.02417973428964615, 'Quản_lý')]\n"
     ]
    }
   ],
   "source": [
    "masked_line = 'Tôi là sinh_viên trường  <mask> ngoại_thương .'\n",
    "topk_filled_outputs = phobert.fill_mask(masked_line, topk=5)\n",
    "print(topk_filled_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerSentenceEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(64001, 768, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(258, 768, padding_idx=1)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (emb_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phobert.eval()  # disable dropout (or leave in train mode to finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens list :  tensor([    0, 11623, 31433,   453, 44334,  2080,  5922,    57,   934,  8181,\n",
      "        31686,  3078,     2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tôn Ngộ Không phò Đường Tăng đi Tây Trúc thỉnh kinh'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Incorporate the BPE encoder into PhoBERT\n",
    "tokens = phobert.encode('Tôn Ngộ Không phò Đường Tăng đi Tây Trúc thỉnh kinh')\n",
    "print('tokens list : ', tokens)\n",
    "# Decode ngược lại thành câu từ chuỗi index token\n",
    "phobert.decode(tokens)  # 'Hello world!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "last_layer_features = phobert.extract_features(tokens)\n",
    "assert last_layer_features.size() == torch.Size([1, 13, 768])\n",
    "assert tokens.size() == torch.Size([13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last layer features:  tensor([[[True, True, True,  ..., True, True, True],\n",
      "         [True, True, True,  ..., True, True, True],\n",
      "         [True, True, True,  ..., True, True, True],\n",
      "         ...,\n",
      "         [True, True, True,  ..., True, True, True],\n",
      "         [True, True, True,  ..., True, True, True],\n",
      "         [True, True, True,  ..., True, True, True]]])\n"
     ]
    }
   ],
   "source": [
    "all_layers = phobert.extract_features(tokens, return_all_hiddens=True)\n",
    "print('Last layer features: ', all_layers[-1] == last_layer_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'segment'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_45236\\902374526.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msegment\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordSegmenter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msegmenter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordSegmenter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Tôn Ngộ Không phò Đường Tăng đi thỉnh kinh tại Tây Trúc'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msegmenter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msegment_string_to_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'segment'"
     ]
    }
   ],
   "source": [
    "from segment import WordSegmenter\n",
    "\n",
    "segmenter = WordSegmenter()\n",
    "text = 'Tôn Ngộ Không phò Đường Tăng đi thỉnh kinh tại Tây Trúc'\n",
    "words = segmenter.segment_string_to_token(text)\n",
    "for i, token in enumerate(words):\n",
    "  if token == 'phò':\n",
    "    words[i] = ' <mask>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\admin\\\\Documents\\\\code\\\\thesis_sentiment_analysis\\\\count_vectorizer',\n",
       " 'C:\\\\Users\\\\admin\\\\anaconda3\\\\envs\\\\thesis-nlp-project\\\\python37.zip',\n",
       " 'C:\\\\Users\\\\admin\\\\anaconda3\\\\envs\\\\thesis-nlp-project\\\\DLLs',\n",
       " 'C:\\\\Users\\\\admin\\\\anaconda3\\\\envs\\\\thesis-nlp-project\\\\lib',\n",
       " 'C:\\\\Users\\\\admin\\\\anaconda3\\\\envs\\\\thesis-nlp-project',\n",
       " '',\n",
       " 'C:\\\\Users\\\\admin\\\\anaconda3\\\\envs\\\\thesis-nlp-project\\\\lib\\\\site-packages',\n",
       " 'c:\\\\users\\\\admin\\\\documents\\\\fairseq',\n",
       " 'C:\\\\Users\\\\admin\\\\anaconda3\\\\envs\\\\thesis-nlp-project\\\\lib\\\\site-packages\\\\torchaudio-0.11.0-py3.7-win-amd64.egg',\n",
       " 'C:\\\\Users\\\\admin\\\\anaconda3\\\\envs\\\\thesis-nlp-project\\\\lib\\\\site-packages\\\\omegaconf-2.0.6-py3.7.egg',\n",
       " 'C:\\\\Users\\\\admin\\\\anaconda3\\\\envs\\\\thesis-nlp-project\\\\lib\\\\site-packages\\\\hydra_core-1.0.7-py3.7.egg',\n",
       " 'C:\\\\Users\\\\admin\\\\anaconda3\\\\envs\\\\thesis-nlp-project\\\\lib\\\\site-packages\\\\fastbpe-0.1.1-py3.7-win-amd64.egg',\n",
       " 'C:\\\\Users\\\\admin\\\\anaconda3\\\\envs\\\\thesis-nlp-project\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\admin\\\\anaconda3\\\\envs\\\\thesis-nlp-project\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\admin\\\\anaconda3\\\\envs\\\\thesis-nlp-project\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\admin\\\\anaconda3\\\\envs\\\\thesis-nlp-project\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\admin\\\\.ipython']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tôn_Ngộ_Không  <mask> Đường Tăng đi thỉnh_kinh tại Tây Trúc'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_masked_tok = ' '.join(words)\n",
    "text_masked_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "words1 = copy(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tôn_Ngộ_Không',\n",
       " ' <mask>',\n",
       " 'Đường',\n",
       " 'Tăng',\n",
       " 'đi',\n",
       " 'thỉnh_kinh',\n",
       " 'tại',\n",
       " 'Tây',\n",
       " 'Tây_Trúc']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words1[8:9] = [\"Tây_Trúc\"]\n",
    "words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tôn_Ngộ_Không  <mask> Đường Tăng đi thỉnh_kinh tại Tây Trúc'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_masked_tok = ' '.join(words)\n",
    "text_masked_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total probability:  0.8698028372600675\n",
      "Input sequence:  Tôn_Ngộ_Không  <mask> Đường Tăng đi thỉnh_kinh tại Tây Trúc\n",
      "Top 10 in mask: \n",
      "Tôn_Ngộ_Không và Đường Tăng đi thỉnh_kinh tại Tây Trúc\n",
      "Tôn_Ngộ_Không đưa Đường Tăng đi thỉnh_kinh tại Tây Trúc\n",
      "Tôn_Ngộ_Không cõng Đường Tăng đi thỉnh_kinh tại Tây Trúc\n",
      "Tôn_Ngộ_Không cùng Đường Tăng đi thỉnh_kinh tại Tây Trúc\n",
      "Tôn_Ngộ_Không hộ_tống Đường Tăng đi thỉnh_kinh tại Tây Trúc\n",
      "Tôn_Ngộ_Không theo Đường Tăng đi thỉnh_kinh tại Tây Trúc\n",
      "Tôn_Ngộ_Không dẫn Đường Tăng đi thỉnh_kinh tại Tây Trúc\n",
      "Tôn_Ngộ_Không chở Đường Tăng đi thỉnh_kinh tại Tây Trúc\n",
      "Tôn_Ngộ_Không , Đường Tăng đi thỉnh_kinh tại Tây Trúc\n",
      "Tôn_Ngộ_Không tháp_tùng Đường Tăng đi thỉnh_kinh tại Tây Trúc\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "topk_filled_outputs = phobert.fill_mask(text_masked_tok, topk=10)\n",
    "topk_probs = [item[1] for item in topk_filled_outputs]\n",
    "print('Total probability: ', np.sum(topk_probs))\n",
    "print('Input sequence: ', text_masked_tok)\n",
    "print('Top 10 in mask: ')\n",
    "for i, output in enumerate(topk_filled_outputs):\n",
    "  print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'EnglishDefaults' has no attribute 'create_tokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22376\\78578142.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphobert\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_features_aligned_to_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"học_sinh cấp 3 được đến trường sau nghỉ dịch covid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\fairseq\\models\\roberta\\hub_interface.py\u001b[0m in \u001b[0;36mextract_features_aligned_to_words\u001b[1;34m(self, sentence, return_all_hiddens)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malignment_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspacy_nlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malignment_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspacy_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;31m# tokenize both with GPT-2 BPE and spaCy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\fairseq\\models\\roberta\\alignment_utils.py\u001b[0m in \u001b[0;36mspacy_tokenizer\u001b[1;34m()\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy_nlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[0mspacy_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDefaults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please install spacy with: pip install spacy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'EnglishDefaults' has no attribute 'create_tokenizer'"
     ]
    }
   ],
   "source": [
    "doc = phobert.extract_features_aligned_to_words(\"học_sinh cấp 3 được đến trường sau nghỉ dịch covid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.3.0-cp37-cp37m-win_amd64.whl (11.9 MB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (3.7.4.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (8.0.15)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (0.7.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (3.0.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.2)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy) (4.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: spacy\n",
      "Successfully installed spacy-3.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting glob2\n",
      "  Downloading glob2-0.7.tar.gz (10 kB)\n",
      "Building wheels for collected packages: glob2\n",
      "  Building wheel for glob2 (setup.py): started\n",
      "  Building wheel for glob2 (setup.py): finished with status 'done'\n",
      "  Created wheel for glob2: filename=glob2-0.7-py2.py3-none-any.whl size=9321 sha256=932d61833b627b553798a1a082d47d8c3da8385606f00cc8e626ea832a26d18f\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\d7\\3c\\72\\5300602ba1269ffce8cff5dcf7b525fee756b57455903c37ba\n",
      "Successfully built glob2\n",
      "Installing collected packages: glob2\n",
      "Successfully installed glob2-0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install glob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob2\n",
    "\n",
    "data_path = r'C:\\Users\\admin\\Documents\\code\\VNTC\\Data\\10Topics\\Ver1.1'\n",
    "train_path = os.path.join(data_path, 'Train_Full', '*', '*.txt')\n",
    "test_path = os.path.join(data_path, 'Test_Full', '*', '*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3791/33759 [00:11<01:35, 312.89it/s]"
     ]
    }
   ],
   "source": [
    "def read_text(path):\n",
    "  with open(path, 'r', encoding='utf-16') as f:\n",
    "    data = f.read()\n",
    "  return data\n",
    "\n",
    "def make_data(path):\n",
    "  texts = []\n",
    "  labels = []\n",
    "  for file_path in tqdm(glob2.glob(path)):\n",
    "      try:\n",
    "          content = read_text(file_path)\n",
    "          label = file_path.split(os.sep)[-2]\n",
    "          texts.append(content)\n",
    "          labels.append(label)\n",
    "      except:\n",
    "          continue\n",
    "  return texts, labels\n",
    "\n",
    "text_train, label_train = make_data(train_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 50373/50373 [02:31<00:00, 332.08it/s]\n"
     ]
    }
   ],
   "source": [
    "text_test, label_test = make_data(test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _save_pkl(path, obj):\n",
    "  with open(path, 'wb') as f:\n",
    "    pickle.dump(obj, f)\n",
    "\n",
    "def _load_pkl(path):\n",
    "  with open(path, 'rb') as f:\n",
    "    obj = pickle.load(f)\n",
    "  return obj\n",
    "\n",
    "# Lưu lại các files\n",
    "# _save_pkl('.\\\\text_train.pkl', text_train)\n",
    "# _save_pkl('.\\\\label_train.pkl', label_train)\n",
    "# _save_pkl('.\\\\text_test.pkl', text_test)\n",
    "# _save_pkl('.\\\\label_test.pkl', label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text_train = _load_pkl('.\\\\text_train.pkl')\n",
    "label_train = _load_pkl('.\\\\label_train.pkl')\n",
    "text_test = _load_pkl('.\\\\text_test.pkl')\n",
    "label_test = _load_pkl('.\\\\label_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' Thành lập dự án POLICY phòng chống HIV/AIDS ở VN (NLĐ)- Quỹ hỗ trợ khẩn cấp về AIDS của Hoa Kỳ vừa thành lập dự án POLICY tại VN với cam kết hỗ trợ Chính phủ và nhân dân VN đối phó HIV/AIDS.Dự án có nhiệm vụ chính là cải thiện công tác phòng chống HIV/AIDS thông qua các lĩnh vực xây dựng chính sách, rà soát các văn bản pháp luật, xây dựng chiến lược quảng bá, xây dựng chương trình đào tạo về phòng chống HIV/AIDS, lên kế hoạch bố trí nguồn lực, huấn luyện và nghiên cứu về phương tiện truyền thông đại chúng, tổ chức các hoạt động nhằm giảm kỳ thị và phân biệt đối xử đối với người có HIV/AIDS... Theo TTXVN, dự án POLICY đặc biệt quan tâm đến công tác truyền thông phòng chống HIV/AIDS, coi đây là một biện pháp tích cực và hữu hiệu trong việc phòng chống có hiệu quả HIV/AIDS. Thời gian tới, dự án POLICY sẽ tiếp tục tổ chức các hoạt động nhằm nâng cao nhận thức cho những người có trách nhiệm với công tác chỉ đạo phòng chống HIV/AIDS.\\n\\n',\n",
       " 'Chinh tri Xa hoi')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[0], label_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 2000.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 tensor encode: [63117  1302 61542  5958    11   915   222   537   933    39], shape: 256\n",
      "x1 tensor decode:  <s>Học_sinh được nghỉ học bắt dầu từ tháng 3 để tránh dịch covid-19</s> <pad> <pad> <pad> <pad> <pad> <\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_sequence_length = 256\n",
    "def convert_lines(lines, vocab, bpe):\n",
    "    '''\n",
    "    :param lines:\n",
    "    :param vocab:\n",
    "    :param bpe:\n",
    "    :return:\n",
    "    '''\n",
    "    outputs = np.zeros((len(lines), max_sequence_length), dtype=np.int32)\n",
    "    eos_id = 2\n",
    "    pad_id = 1\n",
    "    for idx, row in tqdm(enumerate(lines), total=len(lines)):\n",
    "        subwords = bpe.encode('<s>' + row + '</s>')\n",
    "        input_ids = vocab.encode_line(subwords, append_eos=False, add_if_not_exist=False).long().tolist()\n",
    "        if len(input_ids) > max_sequence_length:\n",
    "            input_ids = input_ids[:max_sequence_length]\n",
    "            input_ids[-1] = eos_id\n",
    "        else:\n",
    "            input_ids = input_ids + [pad_id, ] * (max_sequence_length - len(input_ids))\n",
    "        outputs[idx,: ] = np.array(input_ids, dtype=np.int32)\n",
    "    return outputs\n",
    "\n",
    "from fairseq.data import Dictionary\n",
    "\n",
    "vocab = Dictionary()\n",
    "vocab.add_from_file(os.path.join(phobert_base_folder, 'dict.txt'))\n",
    "lines = ['Học_sinh được nghỉ học bắt dầu từ tháng 3 để tránh dịch covid-19', 'số lượng ca nhiễm bệnh đã giảm bắt đầu từ tháng 5 nhờ biện pháp mạnh tay']\n",
    "[x1, x2] = convert_lines(lines, vocab, phobert.bpe)\n",
    "print('x1 tensor encode: {}, shape: {}'.format(x1[:10], x1.size))\n",
    "print('x1 tensor decode: ', phobert.decode(torch.tensor(x1))[:103])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33759/33759 [01:07<00:00, 496.67it/s]\n"
     ]
    }
   ],
   "source": [
    "X = convert_lines(text_train, vocab, phobert.bpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33759, 256)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chinh tri Xa hoi' 'Doi song' 'Khoa hoc' 'Kinh doanh' 'Phap luat'\n",
      " 'Suc khoe' 'The gioi' 'The thao' 'Van hoa' 'Vi tinh']\n",
      "Top 5 class índices [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "lb.fit(label_train)\n",
    "y = lb.fit_transform(label_train)\n",
    "print(lb.classes_)\n",
    "print('Top 5 class índices', y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X:  33759\n",
      "length of y:  33759\n"
     ]
    }
   ],
   "source": [
    "_save_pkl(os.path.join('.', 'PhoBERT_pretrain','X1.pkl'), X)\n",
    "_save_pkl(os.path.join('.', 'PhoBERT_pretrain','y1.pkl'), y)\n",
    "_save_pkl(os.path.join('.', 'PhoBERT_pretrain','labelEncoder1.pkl'), lb)\n",
    "\n",
    "\n",
    "X  = _load_pkl(os.path.join('.', 'PhoBERT_pretrain','X1.pkl'))\n",
    "y  = _load_pkl(os.path.join('.', 'PhoBERT_pretrain','y1.pkl'))\n",
    "print('length of X: ', len(X))\n",
    "print('length of y: ', len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 22:23:03 | INFO | fairseq.file_utils | loading archive file ..\\PhoBERT_base_fairseq\n",
      "2022-05-29 22:23:03 | INFO | fairseq.tasks.masked_lm | dictionary: 64000 types\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0876, -2.2838, -2.2251, -2.1184, -2.5490, -2.2110, -2.4840, -2.2790,\n",
       "         -2.3543, -2.5598]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fairseq.models.roberta import RobertaModel\n",
    "\n",
    "phoBERT_cls = phobert = RobertaModel.from_pretrained(phobert_base_folder, checkpoint_file='model.pt', bpe='fastbpe', bpe_codes=bpe_codes_file)\n",
    "phoBERT_cls.eval()\n",
    "phoBERT_cls.register_classification_head('new_task', num_classes=10)\n",
    "tokens = 'Học_sinh được nghỉ học bắt đầu từ tháng 3 do ảnh hưởng của dịch covid-19'\n",
    "token_idxs = phoBERT_cls.encode(tokens)\n",
    "logprobs = phoBERT_cls.predict('new_task', token_idxs)  # tensor([[-1.1050, -1.0672, -1.1245]], grad_fn=<LogSoftmaxBackward>)\n",
    "logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6666666666666666, 0.5333333333333333)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate(logits, targets):\n",
    "    \"\"\"\n",
    "    Đánh giá model sử dụng cho acuracy và f1-score\n",
    "    :param logits: (B,C) torch.LongTensor  giá trị predicted cho các class output\n",
    "    :param targets: (B) torch.LongTensor actual target indices\n",
    "    :return: acc\n",
    "    f1_score\n",
    "    \"\"\"\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "    targets = targets.detach().cpu().numpy()\n",
    "    f1 = f1_score(targets, y_pred, average='weighted')\n",
    "    acc = accuracy_score(targets, y_pred)\n",
    "    return acc, f1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logits = torch.tensor([[0.1, 0.2, 0.7],\n",
    "                       [0.4, 0.1, 0.5],\n",
    "                       [0.1, 0.2, 0.7]]).to(device)\n",
    "targets = torch.tensor([1, 2, 2]).to(device)\n",
    "evaluate(logits, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def validate(valid_loader, model, device):\n",
    "    model.eval()\n",
    "    accs = []\n",
    "    f1s = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in valid_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            output = model.predict('new_task', x_batch)\n",
    "            logits = torch.exp(output)\n",
    "            acc, f1 = evaluate(logits, y_batch)\n",
    "            accs.append(acc)\n",
    "            f1s.append(f1)\n",
    "    mean_acc = np.mean(accs)\n",
    "    mean_f1 = np.mean(f1s)\n",
    "    return mean_acc, mean_f1\n",
    "\n",
    "\n",
    "def train_on_epoch(train_loader, model, optimizer, epoch, num_epochs, criteria, device, log_aggr=100):\n",
    "    model.train()\n",
    "    sum_epoch_loss = 0\n",
    "    sum_acc =0\n",
    "    sum_f1 = 0\n",
    "    start = time.time()\n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.predict('new_task', x_batch)\n",
    "        logits = torch.exp(y_pred)\n",
    "        acc, f1 = evaluate(logits, y_batch)\n",
    "        loss = criteria(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_val = loss.item()\n",
    "        sum_epoch_loss += loss_val\n",
    "        sum_acc += acc\n",
    "        sum_f1 += f1\n",
    "        iter_num = epoch * len(train_loader) + i + 1\n",
    "        if i % log_aggr == 0:\n",
    "            print('[TRAIN] epoch %d/%d  observation %d/%d batch loss: %.4f (avg %.4f),  avg acc: %.4f, avg f1: %.4f, (%.2f im/s)'\n",
    "                % (epoch + 1, num_epochs, i, len(train_loader), loss_val, sum_epoch_loss / (i + 1),  sum_acc/(i+1), sum_f1/(i+1),\n",
    "                  len(x_batch) / (time.time() - start)))\n",
    "        start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 22:52:44 | INFO | fairseq.file_utils | loading archive file ..\\PhoBERT_base_fairseq\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 4\n",
      "Load model pretrained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 22:52:44 | INFO | fairseq.tasks.masked_lm | dictionary: 64000 types\n",
      "C:\\Users\\admin\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\transformers\\optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Optimizer LayerNorm.bias LayerNorm.Weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "[TRAIN] epoch 1/20  observation 0/4502 batch loss: 2.3040 (avg 2.3040),  avg acc: 0.1667, avg f1: 0.0556, (4.15 im/s)\n",
      "[TRAIN] epoch 1/20  observation 100/4502 batch loss: 2.0727 (avg 2.3996),  avg acc: 0.1254, avg f1: 0.0576, (56.97 im/s)\n",
      "[TRAIN] epoch 1/20  observation 200/4502 batch loss: 2.2240 (avg 2.3643),  avg acc: 0.1202, avg f1: 0.0543, (59.75 im/s)\n",
      "[TRAIN] epoch 1/20  observation 300/4502 batch loss: 2.3677 (avg 2.3419),  avg acc: 0.1318, avg f1: 0.0598, (58.82 im/s)\n",
      "[TRAIN] epoch 1/20  observation 400/4502 batch loss: 2.1800 (avg 2.3293),  avg acc: 0.1367, avg f1: 0.0637, (59.93 im/s)\n",
      "[TRAIN] epoch 1/20  observation 500/4502 batch loss: 2.3317 (avg 2.3193),  avg acc: 0.1420, avg f1: 0.0680, (63.44 im/s)\n",
      "[TRAIN] epoch 1/20  observation 600/4502 batch loss: 2.2112 (avg 2.3117),  avg acc: 0.1459, avg f1: 0.0700, (59.75 im/s)\n",
      "[TRAIN] epoch 1/20  observation 700/4502 batch loss: 2.2590 (avg 2.3080),  avg acc: 0.1462, avg f1: 0.0695, (58.82 im/s)\n",
      "[TRAIN] epoch 1/20  observation 800/4502 batch loss: 2.3049 (avg 2.3040),  avg acc: 0.1475, avg f1: 0.0697, (56.19 im/s)\n",
      "[TRAIN] epoch 1/20  observation 900/4502 batch loss: 2.1643 (avg 2.3000),  avg acc: 0.1467, avg f1: 0.0702, (61.85 im/s)\n",
      "[TRAIN] epoch 1/20  observation 1000/4502 batch loss: 2.2613 (avg 2.2970),  avg acc: 0.1479, avg f1: 0.0712, (60.91 im/s)\n",
      "[TRAIN] epoch 1/20  observation 1100/4502 batch loss: 2.2149 (avg 2.2968),  avg acc: 0.1458, avg f1: 0.0705, (60.61 im/s)\n",
      "[TRAIN] epoch 1/20  observation 1200/4502 batch loss: 2.5271 (avg 2.2961),  avg acc: 0.1438, avg f1: 0.0696, (60.00 im/s)\n",
      "[TRAIN] epoch 1/20  observation 1300/4502 batch loss: 2.3371 (avg 2.2946),  avg acc: 0.1444, avg f1: 0.0698, (59.41 im/s)\n",
      "[TRAIN] epoch 1/20  observation 1400/4502 batch loss: 2.2994 (avg 2.2936),  avg acc: 0.1451, avg f1: 0.0698, (61.86 im/s)\n",
      "[TRAIN] epoch 1/20  observation 1500/4502 batch loss: 2.5079 (avg 2.2904),  avg acc: 0.1463, avg f1: 0.0709, (61.22 im/s)\n",
      "[TRAIN] epoch 1/20  observation 1600/4502 batch loss: 2.2792 (avg 2.2890),  avg acc: 0.1475, avg f1: 0.0714, (61.86 im/s)\n",
      "[TRAIN] epoch 1/20  observation 1700/4502 batch loss: 2.1717 (avg 2.2870),  avg acc: 0.1479, avg f1: 0.0717, (61.86 im/s)\n",
      "[TRAIN] epoch 1/20  observation 1800/4502 batch loss: 2.1915 (avg 2.2865),  avg acc: 0.1469, avg f1: 0.0714, (60.00 im/s)\n",
      "[TRAIN] epoch 1/20  observation 1900/4502 batch loss: 2.3476 (avg 2.2859),  avg acc: 0.1469, avg f1: 0.0715, (58.82 im/s)\n",
      "[TRAIN] epoch 1/20  observation 2000/4502 batch loss: 2.0936 (avg 2.2847),  avg acc: 0.1467, avg f1: 0.0713, (61.23 im/s)\n",
      "[TRAIN] epoch 1/20  observation 2100/4502 batch loss: 2.2482 (avg 2.2840),  avg acc: 0.1476, avg f1: 0.0713, (61.85 im/s)\n",
      "[TRAIN] epoch 1/20  observation 2200/4502 batch loss: 2.1182 (avg 2.2833),  avg acc: 0.1470, avg f1: 0.0709, (59.41 im/s)\n",
      "[TRAIN] epoch 1/20  observation 2300/4502 batch loss: 2.1399 (avg 2.2828),  avg acc: 0.1467, avg f1: 0.0705, (60.00 im/s)\n",
      "[TRAIN] epoch 1/20  observation 2400/4502 batch loss: 2.4144 (avg 2.2821),  avg acc: 0.1472, avg f1: 0.0706, (57.69 im/s)\n",
      "[TRAIN] epoch 1/20  observation 2500/4502 batch loss: 2.0813 (avg 2.2814),  avg acc: 0.1471, avg f1: 0.0706, (60.00 im/s)\n",
      "[TRAIN] epoch 1/20  observation 2600/4502 batch loss: 2.2558 (avg 2.2811),  avg acc: 0.1471, avg f1: 0.0703, (61.22 im/s)\n",
      "[TRAIN] epoch 1/20  observation 2700/4502 batch loss: 2.1799 (avg 2.2801),  avg acc: 0.1474, avg f1: 0.0702, (61.23 im/s)\n",
      "[TRAIN] epoch 1/20  observation 2800/4502 batch loss: 2.4186 (avg 2.2799),  avg acc: 0.1474, avg f1: 0.0704, (62.32 im/s)\n",
      "[TRAIN] epoch 1/20  observation 2900/4502 batch loss: 2.2778 (avg 2.2780),  avg acc: 0.1479, avg f1: 0.0711, (38.23 im/s)\n",
      "[TRAIN] epoch 1/20  observation 3000/4502 batch loss: 2.2145 (avg 2.2774),  avg acc: 0.1481, avg f1: 0.0712, (55.56 im/s)\n",
      "[TRAIN] epoch 1/20  observation 3100/4502 batch loss: 2.2749 (avg 2.2765),  avg acc: 0.1488, avg f1: 0.0714, (59.41 im/s)\n",
      "[TRAIN] epoch 1/20  observation 3200/4502 batch loss: 2.4074 (avg 2.2761),  avg acc: 0.1493, avg f1: 0.0716, (62.50 im/s)\n",
      "[TRAIN] epoch 1/20  observation 3300/4502 batch loss: 2.2992 (avg 2.2756),  avg acc: 0.1502, avg f1: 0.0721, (61.22 im/s)\n",
      "[TRAIN] epoch 1/20  observation 3400/4502 batch loss: 2.2089 (avg 2.2752),  avg acc: 0.1499, avg f1: 0.0720, (61.42 im/s)\n",
      "[TRAIN] epoch 1/20  observation 3500/4502 batch loss: 2.4124 (avg 2.2748),  avg acc: 0.1502, avg f1: 0.0725, (56.29 im/s)\n",
      "[TRAIN] epoch 1/20  observation 3600/4502 batch loss: 2.4157 (avg 2.2738),  avg acc: 0.1501, avg f1: 0.0727, (61.22 im/s)\n",
      "[TRAIN] epoch 1/20  observation 3700/4502 batch loss: 2.3314 (avg 2.2739),  avg acc: 0.1496, avg f1: 0.0728, (61.86 im/s)\n",
      "[TRAIN] epoch 1/20  observation 3800/4502 batch loss: 2.2537 (avg 2.2735),  avg acc: 0.1493, avg f1: 0.0730, (61.86 im/s)\n",
      "[TRAIN] epoch 1/20  observation 3900/4502 batch loss: 2.2867 (avg 2.2728),  avg acc: 0.1495, avg f1: 0.0734, (59.06 im/s)\n",
      "[TRAIN] epoch 1/20  observation 4000/4502 batch loss: 2.3269 (avg 2.2724),  avg acc: 0.1504, avg f1: 0.0739, (57.69 im/s)\n",
      "[TRAIN] epoch 1/20  observation 4100/4502 batch loss: 2.2199 (avg 2.2718),  avg acc: 0.1503, avg f1: 0.0739, (53.57 im/s)\n",
      "[TRAIN] epoch 1/20  observation 4200/4502 batch loss: 2.2052 (avg 2.2713),  avg acc: 0.1506, avg f1: 0.0741, (57.69 im/s)\n",
      "[TRAIN] epoch 1/20  observation 4300/4502 batch loss: 2.2431 (avg 2.2711),  avg acc: 0.1504, avg f1: 0.0740, (58.25 im/s)\n",
      "[TRAIN] epoch 1/20  observation 4400/4502 batch loss: 2.3395 (avg 2.2708),  avg acc: 0.1507, avg f1: 0.0740, (49.53 im/s)\n",
      "[TRAIN] epoch 1/20  observation 4500/4502 batch loss: 2.2742 (avg 2.2706),  avg acc: 0.1510, avg f1: 0.0740, (49.59 im/s)\n",
      "Epoch 0 validation: acc: 0.1544, f1: 0.1543 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [08:07<2:34:14, 487.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "[TRAIN] epoch 2/20  observation 0/4502 batch loss: 2.1403 (avg 2.1403),  avg acc: 0.1667, avg f1: 0.0476, (22.47 im/s)\n",
      "[TRAIN] epoch 2/20  observation 100/4502 batch loss: 2.1325 (avg 2.2703),  avg acc: 0.1337, avg f1: 0.0663, (59.41 im/s)\n",
      "[TRAIN] epoch 2/20  observation 200/4502 batch loss: 2.2235 (avg 2.2736),  avg acc: 0.1534, avg f1: 0.0733, (60.61 im/s)\n",
      "[TRAIN] epoch 2/20  observation 300/4502 batch loss: 2.1713 (avg 2.2739),  avg acc: 0.1528, avg f1: 0.0714, (58.25 im/s)\n",
      "[TRAIN] epoch 2/20  observation 400/4502 batch loss: 2.2497 (avg 2.2705),  avg acc: 0.1550, avg f1: 0.0705, (61.86 im/s)\n",
      "[TRAIN] epoch 2/20  observation 500/4502 batch loss: 2.5557 (avg 2.2660),  avg acc: 0.1560, avg f1: 0.0708, (60.61 im/s)\n",
      "[TRAIN] epoch 2/20  observation 600/4502 batch loss: 2.2183 (avg 2.2652),  avg acc: 0.1559, avg f1: 0.0701, (61.22 im/s)\n",
      "[TRAIN] epoch 2/20  observation 700/4502 batch loss: 2.3573 (avg 2.2647),  avg acc: 0.1524, avg f1: 0.0688, (57.14 im/s)\n",
      "[TRAIN] epoch 2/20  observation 800/4502 batch loss: 2.6344 (avg 2.2639),  avg acc: 0.1548, avg f1: 0.0704, (60.61 im/s)\n",
      "[TRAIN] epoch 2/20  observation 900/4502 batch loss: 2.3103 (avg 2.2618),  avg acc: 0.1567, avg f1: 0.0720, (61.22 im/s)\n",
      "[TRAIN] epoch 2/20  observation 1000/4502 batch loss: 2.5040 (avg 2.2605),  avg acc: 0.1562, avg f1: 0.0723, (59.41 im/s)\n",
      "[TRAIN] epoch 2/20  observation 1100/4502 batch loss: 2.1913 (avg 2.2617),  avg acc: 0.1547, avg f1: 0.0713, (60.00 im/s)\n",
      "[TRAIN] epoch 2/20  observation 1200/4502 batch loss: 2.4364 (avg 2.2612),  avg acc: 0.1538, avg f1: 0.0721, (60.61 im/s)\n",
      "[TRAIN] epoch 2/20  observation 1300/4502 batch loss: 2.4554 (avg 2.2611),  avg acc: 0.1540, avg f1: 0.0726, (60.61 im/s)\n",
      "[TRAIN] epoch 2/20  observation 1400/4502 batch loss: 2.5077 (avg 2.2608),  avg acc: 0.1531, avg f1: 0.0724, (59.41 im/s)\n",
      "[TRAIN] epoch 2/20  observation 1500/4502 batch loss: 2.4396 (avg 2.2600),  avg acc: 0.1541, avg f1: 0.0735, (56.16 im/s)\n",
      "[TRAIN] epoch 2/20  observation 1600/4502 batch loss: 2.3513 (avg 2.2598),  avg acc: 0.1556, avg f1: 0.0738, (59.98 im/s)\n",
      "[TRAIN] epoch 2/20  observation 1700/4502 batch loss: 2.2997 (avg 2.2610),  avg acc: 0.1544, avg f1: 0.0732, (59.94 im/s)\n",
      "[TRAIN] epoch 2/20  observation 1800/4502 batch loss: 2.2608 (avg 2.2614),  avg acc: 0.1525, avg f1: 0.0720, (59.81 im/s)\n",
      "[TRAIN] epoch 2/20  observation 1900/4502 batch loss: 2.1959 (avg 2.2617),  avg acc: 0.1523, avg f1: 0.0723, (59.96 im/s)\n",
      "[TRAIN] epoch 2/20  observation 2000/4502 batch loss: 2.2398 (avg 2.2618),  avg acc: 0.1523, avg f1: 0.0717, (60.07 im/s)\n",
      "[TRAIN] epoch 2/20  observation 2100/4502 batch loss: 2.2101 (avg 2.2605),  avg acc: 0.1540, avg f1: 0.0728, (62.38 im/s)\n",
      "[TRAIN] epoch 2/20  observation 2200/4502 batch loss: 2.5705 (avg 2.2596),  avg acc: 0.1534, avg f1: 0.0728, (59.95 im/s)\n",
      "[TRAIN] epoch 2/20  observation 2300/4502 batch loss: 2.2055 (avg 2.2599),  avg acc: 0.1537, avg f1: 0.0730, (58.30 im/s)\n",
      "[TRAIN] epoch 2/20  observation 2400/4502 batch loss: 2.2386 (avg 2.2605),  avg acc: 0.1531, avg f1: 0.0728, (61.10 im/s)\n",
      "[TRAIN] epoch 2/20  observation 2500/4502 batch loss: 2.4365 (avg 2.2606),  avg acc: 0.1534, avg f1: 0.0733, (55.56 im/s)\n",
      "[TRAIN] epoch 2/20  observation 2600/4502 batch loss: 2.5691 (avg 2.2602),  avg acc: 0.1533, avg f1: 0.0740, (54.05 im/s)\n",
      "[TRAIN] epoch 2/20  observation 2700/4502 batch loss: 2.2040 (avg 2.2607),  avg acc: 0.1524, avg f1: 0.0737, (61.86 im/s)\n",
      "[TRAIN] epoch 2/20  observation 2800/4502 batch loss: 2.2526 (avg 2.2602),  avg acc: 0.1525, avg f1: 0.0737, (60.61 im/s)\n",
      "[TRAIN] epoch 2/20  observation 2900/4502 batch loss: 2.2583 (avg 2.2596),  avg acc: 0.1531, avg f1: 0.0742, (53.10 im/s)\n",
      "[TRAIN] epoch 2/20  observation 3000/4502 batch loss: 2.3834 (avg 2.2585),  avg acc: 0.1540, avg f1: 0.0750, (62.56 im/s)\n",
      "[TRAIN] epoch 2/20  observation 3100/4502 batch loss: 2.2436 (avg 2.2589),  avg acc: 0.1535, avg f1: 0.0749, (59.41 im/s)\n",
      "[TRAIN] epoch 2/20  observation 3200/4502 batch loss: 2.3103 (avg 2.2584),  avg acc: 0.1532, avg f1: 0.0751, (58.82 im/s)\n",
      "[TRAIN] epoch 2/20  observation 3300/4502 batch loss: 2.3581 (avg 2.2587),  avg acc: 0.1533, avg f1: 0.0754, (60.00 im/s)\n",
      "[TRAIN] epoch 2/20  observation 3400/4502 batch loss: 2.2563 (avg 2.2587),  avg acc: 0.1534, avg f1: 0.0759, (58.25 im/s)\n",
      "[TRAIN] epoch 2/20  observation 3500/4502 batch loss: 2.1680 (avg 2.2587),  avg acc: 0.1534, avg f1: 0.0760, (58.82 im/s)\n",
      "[TRAIN] epoch 2/20  observation 3600/4502 batch loss: 2.1401 (avg 2.2587),  avg acc: 0.1534, avg f1: 0.0758, (60.00 im/s)\n",
      "[TRAIN] epoch 2/20  observation 3700/4502 batch loss: 2.1121 (avg 2.2585),  avg acc: 0.1533, avg f1: 0.0756, (60.25 im/s)\n",
      "[TRAIN] epoch 2/20  observation 3800/4502 batch loss: 2.1909 (avg 2.2583),  avg acc: 0.1535, avg f1: 0.0758, (60.61 im/s)\n",
      "[TRAIN] epoch 2/20  observation 3900/4502 batch loss: 2.2172 (avg 2.2582),  avg acc: 0.1535, avg f1: 0.0761, (60.61 im/s)\n",
      "[TRAIN] epoch 2/20  observation 4000/4502 batch loss: 2.1510 (avg 2.2583),  avg acc: 0.1538, avg f1: 0.0761, (57.69 im/s)\n",
      "[TRAIN] epoch 2/20  observation 4100/4502 batch loss: 2.2736 (avg 2.2585),  avg acc: 0.1530, avg f1: 0.0759, (54.56 im/s)\n",
      "[TRAIN] epoch 2/20  observation 4200/4502 batch loss: 2.1968 (avg 2.2586),  avg acc: 0.1534, avg f1: 0.0763, (57.04 im/s)\n",
      "[TRAIN] epoch 2/20  observation 4300/4502 batch loss: 2.2669 (avg 2.2588),  avg acc: 0.1532, avg f1: 0.0759, (55.56 im/s)\n",
      "[TRAIN] epoch 2/20  observation 4400/4502 batch loss: 2.0435 (avg 2.2585),  avg acc: 0.1534, avg f1: 0.0760, (56.08 im/s)\n",
      "[TRAIN] epoch 2/20  observation 4500/4502 batch loss: 2.2829 (avg 2.2589),  avg acc: 0.1534, avg f1: 0.0759, (58.82 im/s)\n",
      "Epoch 1 validation: acc: 0.1567, f1: 0.1566 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [16:15<2:26:17, 487.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n",
      "[TRAIN] epoch 3/20  observation 0/4502 batch loss: 2.1213 (avg 2.1213),  avg acc: 0.1667, avg f1: 0.0476, (21.20 im/s)\n",
      "[TRAIN] epoch 3/20  observation 100/4502 batch loss: 2.1542 (avg 2.2675),  avg acc: 0.1386, avg f1: 0.0575, (56.07 im/s)\n",
      "[TRAIN] epoch 3/20  observation 200/4502 batch loss: 2.1327 (avg 2.2646),  avg acc: 0.1592, avg f1: 0.0714, (54.45 im/s)\n",
      "[TRAIN] epoch 3/20  observation 300/4502 batch loss: 2.2829 (avg 2.2667),  avg acc: 0.1523, avg f1: 0.0684, (62.90 im/s)\n",
      "[TRAIN] epoch 3/20  observation 400/4502 batch loss: 2.1495 (avg 2.2679),  avg acc: 0.1550, avg f1: 0.0701, (60.54 im/s)\n",
      "[TRAIN] epoch 3/20  observation 500/4502 batch loss: 2.2073 (avg 2.2671),  avg acc: 0.1540, avg f1: 0.0689, (60.03 im/s)\n",
      "[TRAIN] epoch 3/20  observation 600/4502 batch loss: 2.4488 (avg 2.2676),  avg acc: 0.1503, avg f1: 0.0661, (59.53 im/s)\n",
      "[TRAIN] epoch 3/20  observation 700/4502 batch loss: 2.2740 (avg 2.2645),  avg acc: 0.1531, avg f1: 0.0675, (60.15 im/s)\n",
      "[TRAIN] epoch 3/20  observation 800/4502 batch loss: 2.2143 (avg 2.2628),  avg acc: 0.1529, avg f1: 0.0680, (60.04 im/s)\n",
      "[TRAIN] epoch 3/20  observation 900/4502 batch loss: 2.3466 (avg 2.2617),  avg acc: 0.1546, avg f1: 0.0697, (60.21 im/s)\n",
      "[TRAIN] epoch 3/20  observation 1000/4502 batch loss: 2.4488 (avg 2.2607),  avg acc: 0.1538, avg f1: 0.0687, (59.95 im/s)\n",
      "[TRAIN] epoch 3/20  observation 1100/4502 batch loss: 2.1509 (avg 2.2605),  avg acc: 0.1559, avg f1: 0.0697, (54.61 im/s)\n",
      "[TRAIN] epoch 3/20  observation 1200/4502 batch loss: 2.3064 (avg 2.2609),  avg acc: 0.1558, avg f1: 0.0692, (59.93 im/s)\n",
      "[TRAIN] epoch 3/20  observation 1300/4502 batch loss: 2.0878 (avg 2.2583),  avg acc: 0.1587, avg f1: 0.0714, (52.11 im/s)\n",
      "[TRAIN] epoch 3/20  observation 1400/4502 batch loss: 2.0941 (avg 2.2580),  avg acc: 0.1588, avg f1: 0.0712, (57.14 im/s)\n",
      "[TRAIN] epoch 3/20  observation 1500/4502 batch loss: 2.1948 (avg 2.2572),  avg acc: 0.1591, avg f1: 0.0710, (59.63 im/s)\n",
      "[TRAIN] epoch 3/20  observation 1600/4502 batch loss: 2.3947 (avg 2.2564),  avg acc: 0.1590, avg f1: 0.0703, (59.68 im/s)\n",
      "[TRAIN] epoch 3/20  observation 1700/4502 batch loss: 2.2353 (avg 2.2558),  avg acc: 0.1579, avg f1: 0.0698, (57.01 im/s)\n",
      "[TRAIN] epoch 3/20  observation 1800/4502 batch loss: 2.4022 (avg 2.2566),  avg acc: 0.1576, avg f1: 0.0695, (60.14 im/s)\n",
      "[TRAIN] epoch 3/20  observation 1900/4502 batch loss: 2.1990 (avg 2.2571),  avg acc: 0.1570, avg f1: 0.0690, (58.76 im/s)\n",
      "[TRAIN] epoch 3/20  observation 2000/4502 batch loss: 2.3735 (avg 2.2563),  avg acc: 0.1583, avg f1: 0.0700, (59.41 im/s)\n",
      "[TRAIN] epoch 3/20  observation 2100/4502 batch loss: 2.2091 (avg 2.2558),  avg acc: 0.1586, avg f1: 0.0702, (60.00 im/s)\n",
      "[TRAIN] epoch 3/20  observation 2200/4502 batch loss: 2.3257 (avg 2.2551),  avg acc: 0.1582, avg f1: 0.0700, (60.13 im/s)\n",
      "[TRAIN] epoch 3/20  observation 2300/4502 batch loss: 2.2357 (avg 2.2557),  avg acc: 0.1584, avg f1: 0.0698, (57.69 im/s)\n",
      "[TRAIN] epoch 3/20  observation 2400/4502 batch loss: 2.2901 (avg 2.2558),  avg acc: 0.1583, avg f1: 0.0697, (54.72 im/s)\n",
      "[TRAIN] epoch 3/20  observation 2500/4502 batch loss: 2.0832 (avg 2.2554),  avg acc: 0.1583, avg f1: 0.0696, (57.33 im/s)\n",
      "[TRAIN] epoch 3/20  observation 2600/4502 batch loss: 2.2637 (avg 2.2555),  avg acc: 0.1578, avg f1: 0.0692, (60.02 im/s)\n",
      "[TRAIN] epoch 3/20  observation 2700/4502 batch loss: 2.1571 (avg 2.2553),  avg acc: 0.1574, avg f1: 0.0691, (59.31 im/s)\n",
      "[TRAIN] epoch 3/20  observation 2800/4502 batch loss: 2.2636 (avg 2.2548),  avg acc: 0.1576, avg f1: 0.0691, (61.22 im/s)\n",
      "[TRAIN] epoch 3/20  observation 2900/4502 batch loss: 2.2159 (avg 2.2553),  avg acc: 0.1572, avg f1: 0.0689, (58.82 im/s)\n",
      "[TRAIN] epoch 3/20  observation 3000/4502 batch loss: 2.5288 (avg 2.2552),  avg acc: 0.1572, avg f1: 0.0689, (60.00 im/s)\n",
      "[TRAIN] epoch 3/20  observation 3100/4502 batch loss: 2.3413 (avg 2.2545),  avg acc: 0.1581, avg f1: 0.0695, (56.60 im/s)\n",
      "[TRAIN] epoch 3/20  observation 3200/4502 batch loss: 2.2155 (avg 2.2547),  avg acc: 0.1576, avg f1: 0.0691, (59.83 im/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [21:43<3:15:33, 651.88s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28944\\755764332.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m                        \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m                        \u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                        log_aggr=100)\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfrozen\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28944\\3760597134.py\u001b[0m in \u001b[0;36mtrain_on_epoch\u001b[1;34m(train_loader, model, optimizer, epoch, num_epochs, criteria, device, log_aggr)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'new_task'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\fairseq\\models\\roberta\\hub_interface.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, head, tokens, return_logits)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_logits\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_heads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_logits\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\fairseq\\models\\roberta\\hub_interface.py\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(self, tokens, return_all_hiddens)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mfeatures_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mreturn_all_hiddens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_all_hiddens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         )\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_all_hiddens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\fairseq\\models\\roberta\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src_tokens, features_only, return_all_hiddens, classification_head_name, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mfeatures_only\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_all_hiddens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclassification_head_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\fairseq\\models\\roberta\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src_tokens, features_only, return_all_hiddens, masked_tokens, **unused)\u001b[0m\n\u001b[0;32m    454\u001b[0m         \"\"\"\n\u001b[0;32m    455\u001b[0m         x, extra = self.extract_features(\n\u001b[1;32m--> 456\u001b[1;33m             \u001b[0msrc_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_all_hiddens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_all_hiddens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m         )\n\u001b[0;32m    458\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfeatures_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\fairseq\\models\\roberta\\model.py\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(self, src_tokens, return_all_hiddens, **kwargs)\u001b[0m\n\u001b[0;32m    464\u001b[0m             \u001b[0msrc_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m             \u001b[0mlast_state_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mreturn_all_hiddens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m             \u001b[0mtoken_embeddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"token_embeddings\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    467\u001b[0m         )\n\u001b[0;32m    468\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# T x B x C -> B x T x C\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\fairseq\\modules\\transformer_sentence_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tokens, segment_labels, last_state_only, positions, token_embeddings)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself_attn_padding_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlast_state_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m                 \u001b[0minner_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\fairseq\\modules\\transformer_sentence_encoder_layer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, self_attn_mask, self_attn_padding_mask)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mkey_padding_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself_attn_padding_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[0mneed_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mattn_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself_attn_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         )\n\u001b[0;32m    123\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\fairseq\\modules\\multihead_attention.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, query, key, value, key_padding_mask, incremental_state, need_weights, static_kv, attn_mask, before_softmax, need_head_weights)\u001b[0m\n\u001b[0;32m    184\u001b[0m                 \u001b[0mq_proj_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq_proj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m                 \u001b[0mk_proj_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m                 \u001b[0mv_proj_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m             )\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)\u001b[0m\n\u001b[0;32m   5252\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5253\u001b[0m             \u001b[0mb_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5254\u001b[1;33m         \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_in_projection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_proj_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_proj_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_proj_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_v\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5256\u001b[0m     \u001b[1;31m# prep attention mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis-nlp-project\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_in_projection\u001b[1;34m(q, k, v, w_q, w_k, w_v, b_q, b_k, b_v)\u001b[0m\n\u001b[0;32m   4994\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mb_k\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mb_k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mEq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"expecting key bias shape of {(Eq,)}, but got {b_k.shape}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4995\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mb_v\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mb_v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mEq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"expecting value bias shape of {(Eq,)}, but got {b_v.shape}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4996\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_v\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from torch import nn\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 6\n",
    "ACCUMULATION_STEPS = 5\n",
    "FOLD = 4\n",
    "LR = 0.0001\n",
    "LR_DC_STEP = 80\n",
    "LR_DC = 0.1\n",
    "CUR_DIR = os.path.dirname(os.getcwd())\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "FOLD = 4\n",
    "CKPT_PATH2 = 'model_ckpt2'\n",
    "\n",
    "if not os.path.exists(CKPT_PATH2):\n",
    "    os.mkdir(CKPT_PATH2)\n",
    "\n",
    "splits = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=123).split(X, y))\n",
    "for fold, (train_idx, val_idx) in enumerate(splits):\n",
    "    best_score = 0\n",
    "    if fold != FOLD:\n",
    "        continue\n",
    "    print(\"Training for fold {}\".format(fold))\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.tensor(X[train_idx], dtype=torch.long), torch.tensor(y[train_idx], dtype=torch.long))\n",
    "    valid_dataset  = torch.utils.data.TensorDataset(torch.tensor(X[val_idx], dtype=torch.long), torch.tensor(y[val_idx], dtype=torch.long))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valid_loader  = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    MODEL_LAST_CKPT = os.path.join(CKPT_PATH2, \"last_checkpoint.pth.tar\")\n",
    "    if os.path.exists(MODEL_LAST_CKPT):\n",
    "        print('Load checkpoint model!')\n",
    "        phoBERT_cls = torch.load(MODEL_LAST_CKPT)\n",
    "    else:\n",
    "        print(\"Load model pretrained\")\n",
    "        phoBERT_cls = RobertaModel.from_pretrained(phobert_base_folder, checkpoint_file='model.pt', bpe='fastbpe', bpe_codes=bpe_codes_file).eval()\n",
    "        phoBERT_cls.eval()  # disable dropout (or leave in train mode to finetune\n",
    "        phoBERT_cls.register_classification_head('new_task', num_classes=10)\n",
    "\n",
    "    phoBERT_cls.to(DEVICE)\n",
    "    param_optimizer = list(phoBERT_cls.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    print(\"Init Optimizer\", \"LayerNorm.bias\", \"LayerNorm.Weight\")\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    num_train_optimization_steps = int(EPOCHS * len(train_dataset)/BATCH_SIZE/ACCUMULATION_STEPS)\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=LR, correct_bias=False)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=num_train_optimization_steps)\n",
    "    scheduler0 = get_constant_schedule(optimizer)\n",
    "\n",
    "    criteria = nn.NLLLoss()\n",
    "    avg_loss = 0\n",
    "    avg_accuracy = 0\n",
    "    frozen = True\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        if epoch > 0 and frozen:\n",
    "            for child in phoBERT_cls.children():\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = True\n",
    "            frozen = False\n",
    "            del scheduler0\n",
    "            torch.cuda.empty_cache()\n",
    "        print(\"Epoch: \", epoch)\n",
    "        train_on_epoch(train_loader=train_loader,\n",
    "                       device=DEVICE,\n",
    "                       model=phoBERT_cls,\n",
    "                       criteria=criteria,\n",
    "                       optimizer=optimizer,\n",
    "                       num_epochs=EPOCHS,\n",
    "                       epoch=epoch,\n",
    "                       log_aggr=100)\n",
    "        if not frozen:\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            scheduler0.step()\n",
    "        optimizer.zero_grad()\n",
    "        acc, f1 = validate(valid_loader, phoBERT_cls, device=DEVICE)\n",
    "\n",
    "        print('Epoch {} validation: acc: {:.4f}, f1: {:.4f} \\n'.format(epoch, acc, f1))\n",
    "        ckpt_dict = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': phoBERT_cls.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict()\n",
    "                }\n",
    "        # Save model checkpoint into 'latest_checkpoint.pth.tar'\n",
    "        torch.save(ckpt_dict, MODEL_LAST_CKPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
